{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.0.0-alpha0\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/39/f99185d39131b8333afcfe1dcdb0629c2ffc4ecfb0e4c14ca210d620e56c/tensorflow-2.0.0a0-cp36-cp36m-manylinux1_x86_64.whl (79.9MB)\r\n",
      "\u001b[K     |████████████████████████████████| 79.9MB 46.8MB/s \r\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.0.0-alpha0) (3.7.1)\r\n",
      "Collecting tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 (from tensorflow==2.0.0-alpha0)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/82/f16063b4eed210dc2ab057930ac1da4fbe1e91b7b051a6c8370b401e6ae7/tf_estimator_nightly-1.14.0.dev2019030115-py2.py3-none-any.whl (411kB)\r\n",
      "\u001b[K     |████████████████████████████████| 419kB 35.2MB/s \r\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.0.0-alpha0) (0.33.6)\r\n",
      "Collecting tb-nightly<1.14.0a20190302,>=1.14.0a20190301 (from tensorflow==2.0.0-alpha0)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/51/aa1d756644bf4624c03844115e4ac4058eff77acd786b26315f051a4b195/tb_nightly-1.14.0a20190301-py3-none-any.whl (3.0MB)\r\n",
      "\u001b[K     |████████████████████████████████| 3.0MB 35.9MB/s \r\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.10.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.0.0-alpha0) (1.12.0)\r\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.0.0-alpha0) (1.1.0)\r\n",
      "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.0.0-alpha0) (1.0.8)\r\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.2 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.0.0-alpha0) (0.1.7)\r\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.0.0-alpha0) (1.24.0)\r\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.0.0-alpha0) (1.1.0)\r\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.0.0-alpha0) (0.8.0)\r\n",
      "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.14.5 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.0.0-alpha0) (1.16.4)\r\n",
      "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.0.0-alpha0) (0.8.0)\r\n",
      "Requirement already satisfied, skipping upgrade: gast>=0.2.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.0.0-alpha0) (0.3.2)\r\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /opt/conda/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow==2.0.0-alpha0) (41.2.0)\r\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /opt/conda/lib/python3.6/site-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0-alpha0) (0.16.0)\r\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /opt/conda/lib/python3.6/site-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0-alpha0) (3.1.1)\r\n",
      "Requirement already satisfied, skipping upgrade: h5py in /opt/conda/lib/python3.6/site-packages (from keras-applications>=1.0.6->tensorflow==2.0.0-alpha0) (2.9.0)\r\n",
      "Installing collected packages: tf-estimator-nightly, tb-nightly, tensorflow\r\n",
      "  Found existing installation: tensorflow 1.14.0\r\n",
      "    Uninstalling tensorflow-1.14.0:\r\n",
      "      Successfully uninstalled tensorflow-1.14.0\r\n",
      "Successfully installed tb-nightly-1.14.0a20190301 tensorflow-2.0.0a0 tf-estimator-nightly-1.14.0.dev2019030115\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/fordham-cs6000-hw/mnist_data/mnist.trainlabel.npy\n",
      "../input/fordham-cs6000-hw/mnist_data/mnist.train.npy\n",
      "../input/fordham-cs6000-hw/mnist_data/mnist.test.npy\n",
      "../input/fordham-cs6000-hw/mnist_data/sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "!pip install -U tensorflow==2.0.0-alpha0\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import keras\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('../input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.load(\"../input/fordham-cs6000-hw/mnist_data/mnist.train.npy\")\n",
    "np.max(x_train) # Our data is already normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 9, ..., 8, 0, 7])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.load(\"../input/fordham-cs6000-hw/mnist_data/mnist.trainlabel.npy\")\n",
    "y_train # We will use one-hot encoding to convert values (0-9) to binary values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = np.load(\"../input/fordham-cs6000-hw/mnist_data/mnist.test.npy\")\n",
    "np.max(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class\n",
       "0      7\n",
       "1      4\n",
       "2      3\n",
       "3      5\n",
       "4      7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = pd.read_csv(\"../input/fordham-cs6000-hw/mnist_data/sample_submission.csv\", usecols = ['class'])\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y_test from DataFrame to Numpy Array\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train size: (56000, 28, 28)\n",
      "y_train size: (56000, 1)\n",
      "x_test size: (28000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Printing dimensions of our x_train and y_train\n",
    "print(\"x_train size:\", x_train.shape) # 56,000 images, each image of 28px by 28px\n",
    "print(\"y_train size:\", y_train.shape) # total classes (0-9 digits)\n",
    "print(\"x_test size:\", x_test.shape) # 28,000 images, each image of 28px by 28px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.One hot encode the labels - scaling the values between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before one-hot encoding:  (56000, 1)\n",
      "Shape after one-hot encoding:  (56000, 10)\n"
     ]
    }
   ],
   "source": [
    "# one-hot encoding using keras' numpy-related utilities\n",
    "from keras.utils import np_utils\n",
    "\n",
    "n_classes = 10\n",
    "print(\"Shape before one-hot encoding: \", y_train.shape)\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, n_classes)\n",
    "Y_test =  np_utils.to_categorical(y_test, n_classes)\n",
    "print(\"Shape after one-hot encoding: \", Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Convert each image matrix ( 28×28 ) to an array ( 28*28 = 784 dimenstional ) which will be fed to the network as a single feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change from matrix to array of dimension 28x28 to array of dimension 784\n",
    "dim_data = np.prod(x_train.shape[1:])\n",
    "X_train = x_train.reshape(x_train.shape[0], dim_data)\n",
    "X_test = x_test.reshape(x_test.shape[0], dim_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train size: (56000, 784)\n",
      "x_test size: (28000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train size:\", X_train.shape) \n",
    "print(\"x_test size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Split training data into a train and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train size: (44800, 784)\n",
      "y_train size: (44800, 10)\n",
      "x_val size: (11200, 784)\n",
      "y_val size: (11200, 10)\n"
     ]
    }
   ],
   "source": [
    "# Train and validation split (80% train, 20% val)\n",
    "X_train, X_val = X_train[:-11200], X_train[-11200:]\n",
    "Y_train, Y_val = Y_train[:-11200], Y_train[-11200:]\n",
    "\n",
    "print(\"x_train size:\", X_train.shape) \n",
    "print(\"y_train size:\", Y_train.shape) \n",
    "print(\"x_val size:\", X_val.shape)\n",
    "print(\"y_val size:\", Y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We want to build a 784(Input)-784(Hidden Layer1)-256(Hidden Layer2)-10(Output) neural net model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_size = 784\n",
    "h2_size = 256\n",
    "h3_size = 10\n",
    "input_size = 784\n",
    "n_samples = X_train.shape[0]\n",
    "\n",
    "# Initialize weights and bias\n",
    "w1 = np.zeros((input_size, h1_size)) + (1/n_samples) # This weight initialization produced bad results\n",
    "b1 = np.zeros((h1_size,1)) \n",
    "w2 = np.zeros((h1_size, h2_size)) + (1/n_samples)\n",
    "b2 = np.zeros((h2_size,1))\n",
    "w3 = np.zeros((h2_size, h3_size)) + (1/n_samples)\n",
    "b3 = np.zeros((h3_size,1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 1) (256, 1) (10, 1)\n"
     ]
    }
   ],
   "source": [
    "print(b1.shape, b2.shape, b3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the softmax activation function\n",
    "# The softmax function will be used only for the output layer activations\n",
    "def softmax(a):\n",
    "    a = a-a.max() # to avoid numerical overflow\n",
    "    exp_a = np.exp(a)\n",
    "    return exp_a/exp_a.sum(axis=1, keepdims=True) # produces an output between 0 and 1\n",
    "# ______________________________________________________________________________________\n",
    "# Define our activation functions and their derivates, using numpy\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_deriv(x):\n",
    "    return 1.0 - np.tanh(x)**2\n",
    "# ______________________________________________________________________________________\n",
    "# Cross-Entropy function \n",
    "def cross_entropy(Y_train, ab3, N):\n",
    "    \"\"\"Y_train: vector of the actual output\n",
    "        a3: vector of the final output predictions\n",
    "        N: number of samples to divide by\"\"\"\n",
    "    log_prob = np.multiply(np.log(ab3), Y_train)\n",
    "    cost = - np.sum(log_prob) / N\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x_train):\n",
    "    # Implement forward propagation \n",
    "    z1 = np.dot(x_train, w1) + b1.T\n",
    "    a1 = np.tanh(z1)\n",
    "    \n",
    "    z2 = np.dot(a1,w2) + b2.T\n",
    "    a2 = np.tanh(z2)\n",
    "    \n",
    "    z3 = np.dot(a2, w3) + b3.T\n",
    "    a3 = softmax(z3) # final output prediction\n",
    "    \n",
    "    return z1, a1, z2, a2, z3, a3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1, a1, z2, a2, z3, a3 = forward(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.302585092994045"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the cross-entropy \n",
    "cross_entropy(Y_train, a3, n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Back propagation\n",
    "def backward(z1, a1, z2, a2, z3, a3, x_train, y_train):\n",
    "    dz3 = a3 - y_train\n",
    "#     print(dz3.shape)\n",
    "    dw3 = (1/n_samples) * np.dot(a2.T, dz3)\n",
    "#     print(dw3.shape)\n",
    "    db3 = (1/n_samples) * np.sum(dz3.T, axis=1, keepdims=True)\n",
    "#     print(db3.shape)\n",
    "    dz2 = np.multiply(np.dot(dz3, w3.T), 1 - np.power(a2, 2))\n",
    "\n",
    "    dw2 = (1/n_samples) * np.dot(a1.T, dz2)\n",
    "    db2 = (1/n_samples) * np.sum(dz2.T, axis=1, keepdims=True)\n",
    "#     print(db2.shape)\n",
    "    dz1 = np.multiply(np.dot(dz2, w2.T), 1 - np.power(a1, 2))\n",
    "    dw1 = (1/n_samples) * np.dot(x_train.T, dz1)\n",
    "    db1 = (1/n_samples) * np.sum(dz1.T, axis=1, keepdims=True)\n",
    "    \n",
    "    return dw3, db3, dw2,  db2, dw1, db1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dw3, db3, dw2,  db2, dw1, db1 = backward(z1, a1, z2, a2, z3, a3, X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Weighs and Biases\n",
    "learning_rate = 0.01\n",
    "\n",
    "w1 = w1 - learning_rate * dw1\n",
    "b1 = b1 - learning_rate * db1\n",
    "w2 = w2 - learning_rate * dw2\n",
    "b2 = b2 - learning_rate * db2\n",
    "w3 = w3 - learning_rate * dw3\n",
    "b3 = b3 - learning_rate * db3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 44800\n",
    "batchSz = 32\n",
    "batchNum = int(n_samples/batchSz)\n",
    "n_epoches = 1\n",
    "learning_rate = 0.1\n",
    "\n",
    "for k in range(0, n_epoches):\n",
    "    for i in range(batchNum):\n",
    "\n",
    "        # mini batch\n",
    "        imgs = X_train[i*batchSz: (i+1)*batchSz]\n",
    "        anss = Y_train[i*batchSz: (i+1)*batchSz]\n",
    "\n",
    "        # forward\n",
    "        z1, a1, z2, a2, z3, a3 = forward(imgs)\n",
    "\n",
    "        # backward\n",
    "        dw3, db3, dw2, db2, dw1, db1 = backward(z1, a1, z2, a2, z3, a3, imgs, anss)\n",
    "\n",
    "        # Update the weights and bias\n",
    "        w1 = w1 - learning_rate * dw1\n",
    "        b1 = b1 - learning_rate * db1\n",
    "        w2 = w2 - learning_rate * dw2\n",
    "        b2 = b2 - learning_rate * db2\n",
    "        w3 = w3 - learning_rate * dw3\n",
    "        b3 = b3 - learning_rate * db3\n",
    "\n",
    "        # print xentropy each 100 minibatches\n",
    "        if i%50 == 0:\n",
    "            zb1, ab1, zb2, ab2, zb3, ab3 = forward(X_train)\n",
    "            cross_entropy(Y_train, ab3, n_samples)\n",
    "#             print(xentropy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  The code below was inpsired from Python Machine Learning - Sebastian Raschka and Vahid Mirjalili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet_Version2(object):\n",
    "    \"\"\" Feedforward neural network / Multi-layer perceptron classifier.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    n_hidden : Number of hidden units.(int)\n",
    "    L2 : Lambda value for L2-regularization. (float - default: 0.)\n",
    "    epochs : Number of passes over the training set.(int - default: 50) \n",
    "    eta : Learning rate. (float - default: 0.01)\n",
    "    shuffle : Shuffles training data every epoch if True to prevent circles. (bool - default: True)\n",
    "    minibatch_size : Number of training samples per minibatch when splitting the training data \n",
    "                    in each epoch for stochastic gradient descent. (int - default: 32)\n",
    "    seed : Random seed for initalizing weights and shuffling. (int - default: 2205)\n",
    "        \n",
    "    Attributes\n",
    "    -----------\n",
    "    eval_ : Dictionary collecting the cost, training accuracy,\n",
    "      and validation accuracy for each epoch during training.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, n_hidden_1=784, n_hidden_2=256, epochs=1, lr=0.01, lambd=1,\n",
    "                 shuffle=True, minibatch_size=32, seed=2205):\n",
    "\n",
    "        self.random = np.random.RandomState(seed)\n",
    "        self.n_hidden_1 = n_hidden_1\n",
    "        self.n_hidden_2 = n_hidden_2\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.shuffle = shuffle\n",
    "        self.minibatch_size = minibatch_size\n",
    "        self.lambd = lambd\n",
    "\n",
    "    def _tanh(self, z):\n",
    "        \"\"\"Compute tanh activation function\"\"\"\n",
    "        return np.tanh(z)\n",
    "    \n",
    "    def _sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def _sigmoid_derivative(self, z):\n",
    "        return self._sigmoid(z) * (1 - self._sigmoid(z))\n",
    "\n",
    "    def _forward(self, X):\n",
    "        \"\"\"Compute forward propagation step\"\"\"\n",
    "\n",
    "        # step 1: net input of hidden layer\n",
    "        z_h1 = np.dot(X, self.w_h1) + self.b_h1\n",
    "\n",
    "        # step 2: activation of hidden layer 1\n",
    "        a_h1 = self._tanh(z_h1)\n",
    "#         a_h1 = self._sigmoid(z_h1)\n",
    "        \n",
    "        # step 3: net input of hidden layer 2        \n",
    "        z_h2 = np.dot(X, self.w_h2) + self.b_h2\n",
    "        \n",
    "        # step 4: activation of hidden layer 2        \n",
    "        a_h2 = self._tanh(z_h2)\n",
    "#         a_h2 = self._sigmoid(z_h2)\n",
    "        \n",
    "\n",
    "        # step 5: net input of output layer\n",
    "        z_out = np.dot(a_h2, self.w_out) + self.b_out\n",
    "\n",
    "        # step 6: activation output layer\n",
    "        a_out = self._softmax(z_out)\n",
    "\n",
    "        return z_h1, a_h1, z_h2, a_h2, z_out, a_out\n",
    "\n",
    "    \n",
    "    def _backward(self, activation):\n",
    "        \n",
    "        return None\n",
    "    \n",
    "\n",
    "    def _softmax(self, a):\n",
    "        \"\"\"Takes an N-dimensional vector of real numbers and \n",
    "        transforms it into a vector in range (0,1) which add up to 1.\"\"\"\n",
    "        a = a-a.max() # to avoid numerical overflow\n",
    "        exp_a = np.exp(a)\n",
    "        return exp_a/exp_a.sum(axis=1, keepdims=True)\n",
    "    \n",
    "    def _cross_entropy(self, y_pred, y_true):\n",
    "        \"\"\"Compute cross entropy loss with softmax.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_true : array, shape = (n_samples, n_labels)\n",
    "            one-hot encoded class labels.\n",
    "        y_pred : array, shape = [n_samples, n_output_units]\n",
    "            Activation of the output layer (forward propagation)\n",
    "\n",
    "        Returns\n",
    "        ---------\n",
    "        loss : (float)\n",
    "        \"\"\"\n",
    "        \n",
    "#         log_prob = np.multiply(np.log(y_pred), y_true)\n",
    "        cost = - np.sum(y_true * np.log(y_pred))/44800 + \\\n",
    "                (np.sum(np.square(self.w_h1)) + np.sum(np.square(self.w_h2)) + np.sum(np.square(self.w_out)))*(self.lambd/(2*44800))\n",
    "\n",
    "\n",
    "        return cost\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        X : array, shape = [n_samples, n_features]\n",
    "            Input layer with original features.\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        y_pred : array, shape = [n_samples]\n",
    "            Predicted class labels.\n",
    "        \"\"\"\n",
    "        z_h1, a_h1, z_h2, a_h2, z_out, a_out = self._forward(X)\n",
    "        y_pred = np.argmax(a_out, axis=1)\n",
    "        return y_pred\n",
    "\n",
    "    def fit(self, X_train, Y_train, X_valid, Y_valid):\n",
    "        \"\"\" Learn weights from training data.\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        X_train : array, shape = [n_samples, n_features]\n",
    "            Input layer with original features.\n",
    "        y_train : array, shape = [n_samples]\n",
    "            Target class labels.\n",
    "        X_valid : array, shape = [n_samples, n_features]\n",
    "            Sample features for validation during training\n",
    "        y_valid : array, shape = [n_samples]\n",
    "            Sample labels for validation during training\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        self\n",
    "        \"\"\"\n",
    "        \n",
    "        # number of neurons for input and output layer\n",
    "        outSz = Y_train.shape[1]  # number of class labels, 10\n",
    "        inSz = X_train.shape[1] # 784\n",
    "        N = X_train.shape[0] # total number of instances in the training data\n",
    "        \n",
    "        ########################\n",
    "        # Weight initialization\n",
    "        ########################\n",
    "\n",
    "        # weights for input -> hidden1\n",
    "        self.b_h1 = np.random.rand(self.n_hidden_1) \n",
    "        self.w_h1 = np.random.rand(inSz, self.n_hidden_1)/np.sqrt(1/inSz)\n",
    "        \n",
    "        # weights for hidden1 -> hidden2\n",
    "        \n",
    "        self.b_h2 = np.zeros(self.n_hidden_2) \n",
    "        self.w_h2 = np.random.rand(self.n_hidden_1, self.n_hidden_2)/np.sqrt(1/inSz)\n",
    "        \n",
    "\n",
    "        # weights for hidden2 -> output\n",
    "        self.b_out = np.zeros(outSz)\n",
    "        self.w_out = np.random.rand(self.n_hidden_2, outSz)/np.sqrt(1/inSz)\n",
    "\n",
    "        epoch_strlen = len(str(self.epochs))  # for progress formatting\n",
    "        self.eval_ = {'cost': [], 'train_acc': [], 'valid_acc': []}\n",
    "\n",
    "        # iterate over training epochs\n",
    "        for i in range(self.epochs):\n",
    "\n",
    "            # iterate over minibatches\n",
    "            indices = np.arange(X_train.shape[0])\n",
    "\n",
    "            if self.shuffle:\n",
    "                self.random.shuffle(indices)\n",
    "\n",
    "            for start_idx in range(0, indices.shape[0] - self.minibatch_size +\n",
    "                                   1, self.minibatch_size):\n",
    "                batch_idx = indices[start_idx:start_idx + self.minibatch_size]\n",
    "\n",
    "                # forward propagation\n",
    "                z_h1, a_h1, z_h2, a_h2, z_out, a_out = self._forward(X_train[batch_idx])\n",
    "                \n",
    "#                 print(z_h1, a_h1, z_h2, a_h2, z_out, a_out)\n",
    "\n",
    "                \n",
    "                ##################\n",
    "                # Backpropagation\n",
    "                ##################\n",
    "                \n",
    "                div = 1/32\n",
    "                \n",
    "                \n",
    "                # \n",
    "                dz_out = a_out - Y_train[batch_idx] # [32,10] -[32,10]\n",
    "                dw_out = div * np.matmul(a_h2.T, dz_out ) + (self.lambd/32)*self.w_out # [256,10] = [256,32]*[32,10]\n",
    "                db_out = div * dz_out # [32, 10]\n",
    "\n",
    "                dz_h2 = np.matmul(dz_out, self.w_out.T) * (1 - np.power(a_h2, 2)) # [32,256] = [32,10]*[256,10]\n",
    "                dw_h2 = div * np.matmul( a_h1.T, dz_h2) + (self.lambd/32)*self.w_h2 # [784, 256] = [784,32]*[32*256]\n",
    "                db_h2 = div * dz_h2            \n",
    "            \n",
    "                dz_h1 = np.matmul(dz_h2, self.w_h2.T ) * (1 - np.power(a_h1, 2)) # [32,784] = \n",
    "                dw_h1 = div * np.matmul(X_train[batch_idx].T, dz_h1) + (self.lambd/32)*self.w_h1 # [784, 784] = [784,32] * [32, 784]\n",
    "                db_h1 = div * dz_h1 \n",
    "                         \n",
    "                # weight updates\n",
    "\n",
    "                self.w_h1 -= self.lr * (dw_h1) # [784, 784]\n",
    "                self.b_h1 -= self.lr * db_h1.sum(axis=0)\n",
    "                \n",
    "                self.w_h2 -= self.lr * (dw_h2) # [784, 256]\n",
    "                self.b_h2 -= self.lr * db_h2.sum(axis=0)\n",
    "                \n",
    "                self.w_out -= self.lr * (dw_out) # [256, 10]\n",
    "                self.b_out -= self.lr * db_out.sum(axis=0)\n",
    "                \n",
    "\n",
    "            #############\n",
    "            # Evaluation\n",
    "            #############\n",
    "\n",
    "            # Evaluation after each epoch during training\n",
    "            z_h1, a_h1, z_h2, a_h2, z_out, a_out = self._forward(X_train)\n",
    "            cost = self._cross_entropy(y_pred=a_out, y_true=Y_train)\n",
    "\n",
    "            y_train_pred = self.predict(X_train)\n",
    "            y_valid_pred = self.predict(X_valid)\n",
    "            \n",
    "\n",
    "            \n",
    "            train_acc = np.sum(y_train_pred == np.argmax(Y_train))/X_train.shape[0]\n",
    "\n",
    "            valid_acc = np.sum(y_valid_pred == np.argmax(Y_valid))/X_valid.shape[0]\n",
    "\n",
    "            print('\\r%0*d/%d | Cost: %.2f '\n",
    "                             '| Train/Valid Acc.: %.2f%%/%.2f%% ' %\n",
    "                             (epoch_strlen, i+1, self.epochs, cost,\n",
    "                              train_acc*100, valid_acc*100))\n",
    "\n",
    "            self.eval_['cost'].append(cost)\n",
    "            self.eval_['train_acc'].append(train_acc)\n",
    "            self.eval_['valid_acc'].append(valid_acc)\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(object):\n",
    "    \"\"\" Feedforward neural network / Multi-layer perceptron classifier.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    n_hidden : Number of hidden units.(int)\n",
    "    L2 : Lambda value for L2-regularization. (float - default: 0.)\n",
    "    epochs : Number of passes over the training set.(int - default: 50) \n",
    "    eta : Learning rate. (float - default: 0.01)\n",
    "    shuffle : Shuffles training data every epoch if True to prevent circles. (bool - default: True)\n",
    "    minibatch_size : Number of training samples per minibatch when splitting the training data \n",
    "                    in each epoch for stochastic gradient descent. (int - default: 32)\n",
    "    seed : Random seed for initalizing weights and shuffling. (int - default: 2205)\n",
    "        \n",
    "    Attributes\n",
    "    -----------\n",
    "    eval_ : Dictionary collecting the cost, training accuracy,\n",
    "      and validation accuracy for each epoch during training.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, n_hidden_1=784, n_hidden_2=256, epochs=1, lr=0.01,\n",
    "                 shuffle=True, minibatch_size=32, seed=2205):\n",
    "\n",
    "        self.random = np.random.RandomState(seed)\n",
    "        self.n_hidden_1 = n_hidden_1\n",
    "        self.n_hidden_2 = n_hidden_2\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.shuffle = shuffle\n",
    "        self.minibatch_size = minibatch_size\n",
    "\n",
    "    def _tanh(self, z):\n",
    "        \"\"\"Compute tanh activation function\"\"\"\n",
    "        return np.tanh(z)\n",
    "    \n",
    "    def _tanh_deriv(self, z):\n",
    "        return 1.0 - np.tanh(z)**2\n",
    "    \n",
    "    def _sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def _sigmoid_derivative(self, z):\n",
    "        return self._sigmoid(z) * (1 - self._sigmoid(z))\n",
    "\n",
    "    def _forward(self, X):\n",
    "        \"\"\"Compute forward propagation step\"\"\"\n",
    "\n",
    "        # step 1: net input of hidden layer\n",
    "        z_h1 = np.dot(X, self.w_h1) + self.b_h1\n",
    "\n",
    "        # step 2: activation of hidden layer 1\n",
    "        a_h1 = self._tanh(z_h1)\n",
    "#         a_h1 = self._sigmoid(z_h1)\n",
    "        \n",
    "        # step 3: net input of hidden layer 2        \n",
    "        z_h2 = np.dot(X, self.w_h2) + self.b_h2\n",
    "        \n",
    "        # step 4: activation of hidden layer 2        \n",
    "        a_h2 = self._tanh(z_h2)\n",
    "#         a_h2 = self._sigmoid(z_h2)\n",
    "\n",
    "        # step 5: net input of output layer\n",
    "        z_out = np.dot(a_h2, self.w_out) + self.b_out\n",
    "\n",
    "        # step 6: activation output layer\n",
    "        a_out = self._softmax(z_out)\n",
    "\n",
    "        return z_h1, a_h1, z_h2, a_h2, z_out, a_out\n",
    "\n",
    "\n",
    "    def _softmax(self, a):\n",
    "        \"\"\"Takes an N-dimensional vector of real numbers and \n",
    "        transforms it into a vector in range (0,1) which add up to 1.\"\"\"\n",
    "        a = a-a.max() # to avoid numerical overflow\n",
    "        exp_a = np.exp(a)\n",
    "        return exp_a/exp_a.sum(axis=1, keepdims=True)\n",
    "    \n",
    "    def _cross_entropy(self, y_pred, y_true, N):\n",
    "        \"\"\"Compute cross entropy loss with softmax.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_true : array, shape = (n_samples, n_labels)\n",
    "            one-hot encoded class labels.\n",
    "        y_pred : array, shape = [n_samples, n_output_units]\n",
    "            Activation of the output layer (forward propagation)\n",
    "\n",
    "        Returns\n",
    "        ---------\n",
    "        loss : (float)\n",
    "        \"\"\"\n",
    "        log_prob = np.multiply(np.log(y_pred), y_true)\n",
    "        cost = - np.sum(log_prob) / N\n",
    "        \n",
    "#         log_prob = y_true * np.log(y_pred)\n",
    "#         cost = - np.sum(log_prob)\n",
    "\n",
    "        return cost\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        X : array, shape = [n_samples, n_features]\n",
    "            Input layer with original features.\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        y_pred : array, shape = [n_samples]\n",
    "            Predicted class labels.\n",
    "        \"\"\"\n",
    "        z_h1, a_h1, z_h2, a_h2, z_out, a_out = self._forward(X)\n",
    "        y_pred = np.argmax(z_out, axis=1)\n",
    "        return y_pred\n",
    "\n",
    "    def fit(self, X_train, y_train, X_valid, y_valid):\n",
    "        \"\"\" Learn weights from training data.\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        X_train : array, shape = [n_samples, n_features]\n",
    "            Input layer with original features.\n",
    "        y_train : array, shape = [n_samples]\n",
    "            Target class labels.\n",
    "        X_valid : array, shape = [n_samples, n_features]\n",
    "            Sample features for validation during training\n",
    "        y_valid : array, shape = [n_samples]\n",
    "            Sample labels for validation during training\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        self\n",
    "        \"\"\"\n",
    "        \n",
    "        # number of neurons for input and output layer\n",
    "        outSz = y_train.shape[1]  # number of class labels, 10\n",
    "        inSz = X_train.shape[1] # 784\n",
    "        N = X_train.shape[0] # total number of instances in the training data\n",
    "        \n",
    "        ########################\n",
    "        # Weight initialization\n",
    "        ########################\n",
    "\n",
    "        # weights for input -> hidden1\n",
    "        self.b_h1 = np.random.rand(self.n_hidden_1) \n",
    "        self.w_h1 = np.random.rand(inSz, self.n_hidden_1)/N\n",
    "        \n",
    "        # weights for hidden1 -> hidden2\n",
    "        \n",
    "        self.b_h2 = np.zeros(self.n_hidden_2) \n",
    "        self.w_h2 = np.random.rand(self.n_hidden_1, self.n_hidden_2)/N\n",
    "\n",
    "        # weights for hidden2 -> output\n",
    "        self.b_out = np.zeros(outSz)\n",
    "        self.w_out = np.random.rand(self.n_hidden_2, outSz)/N\n",
    "\n",
    "        epoch_strlen = len(str(self.epochs))  # for progress formatting\n",
    "        self.eval_ = {'cost': [], 'train_acc': [], 'valid_acc': []}\n",
    "\n",
    "        # iterate over training epochs\n",
    "        for i in range(self.epochs):\n",
    "\n",
    "            # iterate over minibatches\n",
    "            indices = np.arange(X_train.shape[0])\n",
    "\n",
    "            if self.shuffle:\n",
    "                self.random.shuffle(indices)\n",
    "\n",
    "            for start_idx in range(0, indices.shape[0] - self.minibatch_size +\n",
    "                                   1, self.minibatch_size):\n",
    "                batch_idx = indices[start_idx:start_idx + self.minibatch_size]\n",
    "\n",
    "                # forward propagation\n",
    "                z_h1, a_h1, z_h2, a_h2, z_out, a_out = self._forward(X_train[batch_idx])\n",
    "#                 print(z_h1, a_h1, z_h2, a_h2, z_out, a_out)\n",
    "\n",
    "                ##################\n",
    "                # Backpropagation\n",
    "                ##################\n",
    "                \n",
    "                div = 1\n",
    "                \n",
    "                dz_out = a_out - y_train[batch_idx]\n",
    "                dw_out = div * np.dot(a_h2.T, dz_out)\n",
    "                db_out = div * dz_out\n",
    "    \n",
    "                dz_h2 = np.multiply(np.dot(dz_out, self.w_out.T), self._tanh_deriv(a_h2))\n",
    "                dw_h2 = div * np.dot(a_h1.T, dz_h2)\n",
    "                db_h2 = div * dz_h2        \n",
    "            \n",
    "                dz_h1 = np.multiply(np.dot(dz_h2, self.w_h2.T), self._tanh_deriv(a_h1))\n",
    "                dw_h1 = div * np.dot(X_train[batch_idx].T, dz_h1)\n",
    "                db_h1 = div * dz_h1\n",
    "                         \n",
    "                # weight updates\n",
    "\n",
    "                self.w_h1 -= self.lr * (dw_h1) \n",
    "                self.b_h1 -= self.lr * db_h1.sum(axis=0)\n",
    "                \n",
    "                self.w_h2 -= self.lr * (dw_h2) \n",
    "                self.b_h2 -= self.lr * db_h2.sum(axis=0)\n",
    "                \n",
    "                self.w_out -= self.lr * (dw_out)\n",
    "                self.b_out -= self.lr * db_out.sum(axis=0)\n",
    "\n",
    "            #############\n",
    "            # Evaluation\n",
    "            #############\n",
    "\n",
    "            # Evaluation after each epoch during training\n",
    "            z_h1, a_h1, z_h2, a_h2, z_out, a_out = self._forward(X_train)\n",
    "            cost = self._cross_entropy(y_pred=a_out, y_true=y_train, N=N)\n",
    "\n",
    "            y_train_pred = self.predict(X_train)\n",
    "            y_valid_pred = self.predict(X_valid)\n",
    "            \n",
    "            \n",
    "            train_acc = np.sum(y_train_pred == np.argmax(y_train, 1))/N\n",
    "    \n",
    "            valid_acc = np.sum(y_valid_pred == np.argmax(y_valid, 1))/N\n",
    "\n",
    "#             print(y_train_pred.shape, y_train.shape)\n",
    "\n",
    "#             print(train_acc, valid_acc)\n",
    "\n",
    "            print('\\r%0*d/%d | Cost: %.2f '\n",
    "                             '| Train/Valid Acc.: %.2f%%/%.2f%% ' %\n",
    "                             (epoch_strlen, i+1, self.epochs, cost,\n",
    "                              train_acc*100, valid_acc*100))\n",
    "\n",
    "            self.eval_['cost'].append(cost)\n",
    "            self.eval_['train_acc'].append(train_acc)\n",
    "            self.eval_['valid_acc'].append(valid_acc)\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_V2 = NeuralNet_Version2(n_hidden_1=784, n_hidden_2=256, epochs=50, lr=0.01, lambd=1, shuffle=True, minibatch_size=32, seed=2205)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/50 | Cost: 995.82 | Train/Valid Acc.: 0.00%/100.00% \n",
      "02/50 | Cost: 416.42 | Train/Valid Acc.: 0.00%/100.00% \n",
      "03/50 | Cost: 174.92 | Train/Valid Acc.: 0.00%/0.00% \n",
      "04/50 | Cost: 74.25 | Train/Valid Acc.: 0.00%/0.00% \n",
      "05/50 | Cost: 32.31 | Train/Valid Acc.: 0.00%/0.00% \n",
      "06/50 | Cost: 14.81 | Train/Valid Acc.: 0.00%/0.00% \n",
      "07/50 | Cost: 7.54 | Train/Valid Acc.: 0.00%/0.00% \n",
      "08/50 | Cost: 4.49 | Train/Valid Acc.: 0.00%/0.00% \n",
      "09/50 | Cost: 3.23 | Train/Valid Acc.: 0.00%/0.00% \n",
      "10/50 | Cost: 2.69 | Train/Valid Acc.: 0.00%/0.00% \n",
      "11/50 | Cost: 2.47 | Train/Valid Acc.: 0.00%/0.00% \n",
      "12/50 | Cost: 2.40 | Train/Valid Acc.: 0.00%/0.00% \n",
      "13/50 | Cost: 2.36 | Train/Valid Acc.: 0.00%/0.00% \n",
      "14/50 | Cost: 2.30 | Train/Valid Acc.: 0.00%/0.00% \n",
      "15/50 | Cost: 2.15 | Train/Valid Acc.: 0.00%/2.74% \n",
      "16/50 | Cost: 2.08 | Train/Valid Acc.: 5.87%/9.67% \n",
      "17/50 | Cost: 1.97 | Train/Valid Acc.: 0.00%/0.00% \n",
      "18/50 | Cost: 1.83 | Train/Valid Acc.: 0.36%/9.76% \n",
      "19/50 | Cost: 1.69 | Train/Valid Acc.: 7.59%/10.38% \n",
      "20/50 | Cost: 1.69 | Train/Valid Acc.: 0.78%/13.52% \n",
      "21/50 | Cost: 1.74 | Train/Valid Acc.: 1.71%/15.73% \n",
      "22/50 | Cost: 1.75 | Train/Valid Acc.: 4.26%/13.51% \n",
      "23/50 | Cost: 1.75 | Train/Valid Acc.: 4.44%/13.71% \n",
      "24/50 | Cost: 1.71 | Train/Valid Acc.: 6.50%/12.23% \n",
      "25/50 | Cost: 1.68 | Train/Valid Acc.: 8.17%/11.02% \n",
      "26/50 | Cost: 1.66 | Train/Valid Acc.: 5.45%/12.85% \n",
      "27/50 | Cost: 1.65 | Train/Valid Acc.: 4.06%/12.40% \n",
      "28/50 | Cost: 1.64 | Train/Valid Acc.: 6.20%/10.62% \n",
      "29/50 | Cost: 1.64 | Train/Valid Acc.: 7.62%/12.61% \n",
      "30/50 | Cost: 1.62 | Train/Valid Acc.: 6.94%/13.40% \n",
      "31/50 | Cost: 1.61 | Train/Valid Acc.: 9.14%/11.24% \n",
      "32/50 | Cost: 1.62 | Train/Valid Acc.: 9.05%/11.19% \n",
      "33/50 | Cost: 1.62 | Train/Valid Acc.: 7.03%/12.67% \n",
      "34/50 | Cost: 1.62 | Train/Valid Acc.: 7.47%/11.37% \n",
      "35/50 | Cost: 1.62 | Train/Valid Acc.: 6.57%/10.71% \n",
      "36/50 | Cost: 1.62 | Train/Valid Acc.: 5.82%/14.43% \n",
      "37/50 | Cost: 1.62 | Train/Valid Acc.: 8.13%/12.10% \n",
      "38/50 | Cost: 1.63 | Train/Valid Acc.: 8.07%/9.29% \n",
      "39/50 | Cost: 1.63 | Train/Valid Acc.: 7.93%/12.11% \n",
      "40/50 | Cost: 1.63 | Train/Valid Acc.: 4.90%/11.30% \n",
      "41/50 | Cost: 1.64 | Train/Valid Acc.: 5.81%/14.85% \n",
      "42/50 | Cost: 1.63 | Train/Valid Acc.: 4.86%/10.23% \n",
      "43/50 | Cost: 1.64 | Train/Valid Acc.: 6.51%/11.18% \n",
      "44/50 | Cost: 1.64 | Train/Valid Acc.: 4.39%/10.38% \n",
      "45/50 | Cost: 1.64 | Train/Valid Acc.: 6.25%/9.04% \n",
      "46/50 | Cost: 1.64 | Train/Valid Acc.: 5.42%/9.70% \n",
      "47/50 | Cost: 1.64 | Train/Valid Acc.: 4.75%/12.91% \n",
      "48/50 | Cost: 1.64 | Train/Valid Acc.: 6.23%/9.61% \n",
      "49/50 | Cost: 1.64 | Train/Valid Acc.: 5.56%/10.90% \n",
      "50/50 | Cost: 1.64 | Train/Valid Acc.: 6.33%/8.69% \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.NeuralNet_Version2 at 0x7fe77aa170f0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_V2.fit(X_train, Y_train, X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = NeuralNet(n_hidden_1=784, n_hidden_2=256, epochs=50, lr=0.01, shuffle=True, minibatch_size=32, seed=2205)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN.fit(X_train, Y_train, X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = NN_V2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Y_Pred\n",
       "0       1\n",
       "1       6\n",
       "2       7\n",
       "3       7\n",
       "4       1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert y_pred 1D Numpy Array to List\n",
    "y_pred = y_pred.tolist()\n",
    "\n",
    "# # # Flatten list of lists\n",
    "# # Q3_pred_flat = list(np.concatenate(Q3_pred))\n",
    "\n",
    "y_pred = pd.DataFrame({\"Y_Pred\": y_pred})\n",
    "y_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions to CSV file\n",
    "y_pred.to_csv('Q3_prediction.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-alpha0'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n"
     ]
    }
   ],
   "source": [
    "# Define initialization parameters for our model.\n",
    "num_classes = 10\n",
    "num_features = X_train.shape[1] # 784\n",
    "num_output = 10\n",
    "num_layers_1 = 784\n",
    "num_layers_2 = 256\n",
    "learning_rate = 0.01\n",
    "\n",
    "print(num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Reference: Videos from data camp - https://www.datacamp.com/courses/deep-learning-with-keras-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras import optimizers\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "def seed_everything(SEED=2205):\n",
    "    np.random.seed(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    random.seed(SEED)\n",
    "    \n",
    "seed_everything(2205)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the constructor\n",
    "model = Sequential()\n",
    "\n",
    "# Add an input layer with 784 neurons and tanh activation\n",
    "model.add(Dense(num_features, activation='tanh', input_shape=(num_features,)))\n",
    "\n",
    "# Add one hidden layer with 256 neurons and tanh activation\n",
    "model.add(Dense(num_layers_2, activation='tanh'))\n",
    "\n",
    "# Add an output layer with 10 neurons and softmax activation \n",
    "model.add(Dense(num_output, activation='softmax'))\n",
    "\n",
    "#Compiling the sequential model \n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.01),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.optimizer.get_config()\n",
    "\n",
    "# {'name': 'Adam',\n",
    "#  'learning_rate': 0.01,\n",
    "#  'decay': 0.0,\n",
    "#  'beta_1': 0.9,\n",
    "#  'beta_2': 0.999,\n",
    "#  'epsilon': 1e-07,\n",
    "#  'amsgrad': False}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we compiled our model we can start the training process. We want to iterate on the whole training set (epochs = 50) and specify number of samples to use for one update to the model's weights (batch size). Generally the bigger the batch, the more stable our stochastic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 44800 samples, validate on 11200 samples\n",
      "Epoch 1/50\n",
      "44800/44800 [==============================] - 9s 205us/sample - loss: 0.5066 - accuracy: 0.8460 - val_loss: 0.6247 - val_accuracy: 0.8151\n",
      "Epoch 2/50\n",
      "44800/44800 [==============================] - 10s 216us/sample - loss: 0.6177 - accuracy: 0.8074 - val_loss: 0.5418 - val_accuracy: 0.8266\n",
      "Epoch 3/50\n",
      "44800/44800 [==============================] - 9s 204us/sample - loss: 0.6488 - accuracy: 0.8018 - val_loss: 0.6135 - val_accuracy: 0.8274\n",
      "Epoch 4/50\n",
      "44800/44800 [==============================] - 9s 193us/sample - loss: 0.6220 - accuracy: 0.8136 - val_loss: 0.5896 - val_accuracy: 0.8185\n",
      "Epoch 5/50\n",
      "44800/44800 [==============================] - 9s 197us/sample - loss: 0.6818 - accuracy: 0.7956 - val_loss: 0.5957 - val_accuracy: 0.8335\n",
      "Epoch 6/50\n",
      "44800/44800 [==============================] - 9s 202us/sample - loss: 0.6337 - accuracy: 0.8123 - val_loss: 0.5276 - val_accuracy: 0.8631\n",
      "Epoch 7/50\n",
      "44800/44800 [==============================] - 9s 211us/sample - loss: 0.6447 - accuracy: 0.8116 - val_loss: 0.5418 - val_accuracy: 0.8435\n",
      "Epoch 8/50\n",
      "44800/44800 [==============================] - 9s 197us/sample - loss: 0.6053 - accuracy: 0.8293 - val_loss: 0.5552 - val_accuracy: 0.8512\n",
      "Epoch 9/50\n",
      "44800/44800 [==============================] - 9s 199us/sample - loss: 0.5971 - accuracy: 0.8293 - val_loss: 0.5318 - val_accuracy: 0.8557\n",
      "Epoch 10/50\n",
      "44800/44800 [==============================] - 9s 195us/sample - loss: 0.5432 - accuracy: 0.8479 - val_loss: 0.4715 - val_accuracy: 0.8632\n",
      "Epoch 11/50\n",
      "44800/44800 [==============================] - 9s 193us/sample - loss: 0.6079 - accuracy: 0.8267 - val_loss: 0.6151 - val_accuracy: 0.8227\n",
      "Epoch 12/50\n",
      "44800/44800 [==============================] - 9s 199us/sample - loss: 0.6054 - accuracy: 0.8276 - val_loss: 0.7932 - val_accuracy: 0.7508\n",
      "Epoch 13/50\n",
      "44800/44800 [==============================] - 9s 197us/sample - loss: 0.6727 - accuracy: 0.8009 - val_loss: 0.6781 - val_accuracy: 0.8034\n",
      "Epoch 14/50\n",
      "44800/44800 [==============================] - 9s 196us/sample - loss: 0.5956 - accuracy: 0.8384 - val_loss: 0.5778 - val_accuracy: 0.8352\n",
      "Epoch 15/50\n",
      "44800/44800 [==============================] - 9s 199us/sample - loss: 0.5742 - accuracy: 0.8433 - val_loss: 0.5541 - val_accuracy: 0.8484\n",
      "Epoch 16/50\n",
      "44800/44800 [==============================] - 9s 199us/sample - loss: 0.5634 - accuracy: 0.8451 - val_loss: 0.6291 - val_accuracy: 0.8196\n",
      "Epoch 17/50\n",
      "44800/44800 [==============================] - 9s 195us/sample - loss: 0.5455 - accuracy: 0.8474 - val_loss: 0.5676 - val_accuracy: 0.8285\n",
      "Epoch 18/50\n",
      "44800/44800 [==============================] - 9s 198us/sample - loss: 0.5379 - accuracy: 0.8548 - val_loss: 0.4959 - val_accuracy: 0.8719\n",
      "Epoch 19/50\n",
      "44800/44800 [==============================] - 9s 196us/sample - loss: 0.5585 - accuracy: 0.8490 - val_loss: 0.5484 - val_accuracy: 0.8553\n",
      "Epoch 20/50\n",
      "44800/44800 [==============================] - 9s 192us/sample - loss: 0.5554 - accuracy: 0.8497 - val_loss: 0.6176 - val_accuracy: 0.8368\n",
      "Epoch 21/50\n",
      "44800/44800 [==============================] - 9s 192us/sample - loss: 0.5203 - accuracy: 0.8545 - val_loss: 0.5572 - val_accuracy: 0.8153\n",
      "Epoch 22/50\n",
      "44800/44800 [==============================] - 9s 199us/sample - loss: 0.5557 - accuracy: 0.8490 - val_loss: 0.5362 - val_accuracy: 0.8467\n",
      "Epoch 23/50\n",
      "44800/44800 [==============================] - 9s 199us/sample - loss: 0.5413 - accuracy: 0.8573 - val_loss: 0.4858 - val_accuracy: 0.8728\n",
      "Epoch 24/50\n",
      "44800/44800 [==============================] - 9s 198us/sample - loss: 0.5455 - accuracy: 0.8567 - val_loss: 0.6415 - val_accuracy: 0.8429\n",
      "Epoch 25/50\n",
      "44800/44800 [==============================] - 9s 194us/sample - loss: 0.5278 - accuracy: 0.8618 - val_loss: 0.5093 - val_accuracy: 0.8704\n",
      "Epoch 26/50\n",
      "44800/44800 [==============================] - 9s 199us/sample - loss: 0.5056 - accuracy: 0.8606 - val_loss: 0.6144 - val_accuracy: 0.8446\n",
      "Epoch 27/50\n",
      "44800/44800 [==============================] - 9s 203us/sample - loss: 0.4808 - accuracy: 0.8757 - val_loss: 0.4533 - val_accuracy: 0.8815\n",
      "Epoch 28/50\n",
      "44800/44800 [==============================] - 9s 203us/sample - loss: 0.5082 - accuracy: 0.8653 - val_loss: 0.5514 - val_accuracy: 0.8621\n",
      "Epoch 29/50\n",
      "44800/44800 [==============================] - 9s 200us/sample - loss: 0.5235 - accuracy: 0.8606 - val_loss: 0.4918 - val_accuracy: 0.8768\n",
      "Epoch 30/50\n",
      "44800/44800 [==============================] - 9s 200us/sample - loss: 0.4992 - accuracy: 0.8722 - val_loss: 0.5018 - val_accuracy: 0.8729\n",
      "Epoch 31/50\n",
      "44800/44800 [==============================] - 10s 218us/sample - loss: 0.4938 - accuracy: 0.8687 - val_loss: 0.4629 - val_accuracy: 0.8822\n",
      "Epoch 32/50\n",
      "44800/44800 [==============================] - 9s 197us/sample - loss: 0.5074 - accuracy: 0.8667 - val_loss: 0.4671 - val_accuracy: 0.8607\n",
      "Epoch 33/50\n",
      "44800/44800 [==============================] - 9s 195us/sample - loss: 0.5286 - accuracy: 0.8597 - val_loss: 0.4884 - val_accuracy: 0.8599\n",
      "Epoch 34/50\n",
      "44800/44800 [==============================] - 9s 201us/sample - loss: 0.5399 - accuracy: 0.8555 - val_loss: 0.5336 - val_accuracy: 0.8609\n",
      "Epoch 35/50\n",
      "44800/44800 [==============================] - 9s 197us/sample - loss: 0.5077 - accuracy: 0.8661 - val_loss: 0.4685 - val_accuracy: 0.8759\n",
      "Epoch 36/50\n",
      "44800/44800 [==============================] - 9s 198us/sample - loss: 0.5276 - accuracy: 0.8596 - val_loss: 0.4897 - val_accuracy: 0.8731\n",
      "Epoch 37/50\n",
      "44800/44800 [==============================] - 10s 218us/sample - loss: 0.4790 - accuracy: 0.8738 - val_loss: 0.4413 - val_accuracy: 0.8777\n",
      "Epoch 38/50\n",
      "44800/44800 [==============================] - 9s 205us/sample - loss: 0.4948 - accuracy: 0.8703 - val_loss: 0.6722 - val_accuracy: 0.8543\n",
      "Epoch 39/50\n",
      "44800/44800 [==============================] - 9s 198us/sample - loss: 0.5118 - accuracy: 0.8637 - val_loss: 0.4232 - val_accuracy: 0.8964\n",
      "Epoch 40/50\n",
      "44800/44800 [==============================] - 9s 198us/sample - loss: 0.5170 - accuracy: 0.8621 - val_loss: 0.4338 - val_accuracy: 0.8854\n",
      "Epoch 41/50\n",
      "44800/44800 [==============================] - 9s 202us/sample - loss: 0.4608 - accuracy: 0.8798 - val_loss: 0.3878 - val_accuracy: 0.8975\n",
      "Epoch 42/50\n",
      "44800/44800 [==============================] - 9s 192us/sample - loss: 0.4860 - accuracy: 0.8708 - val_loss: 0.4574 - val_accuracy: 0.8884\n",
      "Epoch 43/50\n",
      "44800/44800 [==============================] - 9s 198us/sample - loss: 0.4839 - accuracy: 0.8754 - val_loss: 0.5732 - val_accuracy: 0.8547\n",
      "Epoch 44/50\n",
      "44800/44800 [==============================] - 9s 191us/sample - loss: 0.4944 - accuracy: 0.8696 - val_loss: 0.5845 - val_accuracy: 0.8628\n",
      "Epoch 45/50\n",
      "44800/44800 [==============================] - 9s 192us/sample - loss: 0.4828 - accuracy: 0.8766 - val_loss: 0.6316 - val_accuracy: 0.8579\n",
      "Epoch 46/50\n",
      "44800/44800 [==============================] - 9s 193us/sample - loss: 0.4999 - accuracy: 0.8702 - val_loss: 0.5004 - val_accuracy: 0.8771\n",
      "Epoch 47/50\n",
      "44800/44800 [==============================] - 9s 195us/sample - loss: 0.4837 - accuracy: 0.8760 - val_loss: 0.4608 - val_accuracy: 0.8861\n",
      "Epoch 48/50\n",
      "44800/44800 [==============================] - 9s 193us/sample - loss: 0.4545 - accuracy: 0.8842 - val_loss: 0.5832 - val_accuracy: 0.8506\n",
      "Epoch 49/50\n",
      "44800/44800 [==============================] - 9s 196us/sample - loss: 0.4863 - accuracy: 0.8737 - val_loss: 0.4036 - val_accuracy: 0.9029\n",
      "Epoch 50/50\n",
      "44800/44800 [==============================] - 9s 193us/sample - loss: 0.4794 - accuracy: 0.8779 - val_loss: 0.4162 - val_accuracy: 0.8987\n",
      "Time:  445.8357223590001\n"
     ]
    }
   ],
   "source": [
    "# Start running time\n",
    "start = timeit.default_timer()\n",
    "\n",
    "# Train the model for 50 epochs and save metrics in metrics\n",
    "metrics = model.fit(X_train, Y_train,\n",
    "          batch_size=32, epochs=50,\n",
    "          validation_data=(X_val, Y_val))\n",
    "\n",
    "# Stop running time\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print(\"Time: \", stop - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Train on 44800 samples, validate on 11200 samples\n",
    "    Epoch 1/50\n",
    "    44800/44800 - 7s - loss: 0.5066 - accuracy: 0.8460 - val_loss: 0.6247 - val_accuracy: 0.8151\n",
    "    Epoch 2/50\n",
    "    44800/44800 - 7s - loss: 0.6177 - accuracy: 0.8074 - val_loss: 0.5418 - val_accuracy: 0.8266\n",
    "    Epoch 3/50\n",
    "    44800/44800 - 7s - loss: 0.6488 - accuracy: 0.8018 - val_loss: 0.6135 - val_accuracy: 0.8274\n",
    "    Epoch 4/50\n",
    "    44800/44800 - 7s - loss: 0.6220 - accuracy: 0.8136 - val_loss: 0.5896 - val_accuracy: 0.8185\n",
    "    Epoch 5/50\n",
    "    44800/44800 - 7s - loss: 0.6818 - accuracy: 0.7956 - val_loss: 0.5957 - val_accuracy: 0.8335\n",
    "    Epoch 6/50\n",
    "    44800/44800 - 7s - loss: 0.6337 - accuracy: 0.8123 - val_loss: 0.5276 - val_accuracy: 0.8631\n",
    "    Epoch 7/50\n",
    "    44800/44800 - 7s - loss: 0.6447 - accuracy: 0.8116 - val_loss: 0.5418 - val_accuracy: 0.8435\n",
    "    Epoch 8/50\n",
    "    44800/44800 - 7s - loss: 0.6053 - accuracy: 0.8293 - val_loss: 0.5552 - val_accuracy: 0.8512\n",
    "    Epoch 9/50\n",
    "    44800/44800 - 7s - loss: 0.5971 - accuracy: 0.8293 - val_loss: 0.5318 - val_accuracy: 0.8557\n",
    "    Epoch 10/50\n",
    "    44800/44800 - 7s - loss: 0.5432 - accuracy: 0.8479 - val_loss: 0.4715 - val_accuracy: 0.8632\n",
    "    Epoch 11/50\n",
    "    44800/44800 - 7s - loss: 0.6079 - accuracy: 0.8267 - val_loss: 0.6151 - val_accuracy: 0.8227\n",
    "    Epoch 12/50\n",
    "    44800/44800 - 7s - loss: 0.6054 - accuracy: 0.8276 - val_loss: 0.7932 - val_accuracy: 0.7508\n",
    "    Epoch 13/50\n",
    "    44800/44800 - 7s - loss: 0.6727 - accuracy: 0.8009 - val_loss: 0.6781 - val_accuracy: 0.8034\n",
    "    Epoch 14/50\n",
    "    44800/44800 - 7s - loss: 0.5956 - accuracy: 0.8384 - val_loss: 0.5778 - val_accuracy: 0.8352\n",
    "    Epoch 15/50\n",
    "    44800/44800 - 7s - loss: 0.5742 - accuracy: 0.8433 - val_loss: 0.5541 - val_accuracy: 0.8484\n",
    "    Epoch 16/50\n",
    "    44800/44800 - 7s - loss: 0.5634 - accuracy: 0.8451 - val_loss: 0.6291 - val_accuracy: 0.8196\n",
    "    Epoch 17/50\n",
    "    44800/44800 - 7s - loss: 0.5455 - accuracy: 0.8474 - val_loss: 0.5676 - val_accuracy: 0.8285\n",
    "    Epoch 18/50\n",
    "    44800/44800 - 7s - loss: 0.5379 - accuracy: 0.8548 - val_loss: 0.4959 - val_accuracy: 0.8719\n",
    "    Epoch 19/50\n",
    "    44800/44800 - 7s - loss: 0.5585 - accuracy: 0.8490 - val_loss: 0.5484 - val_accuracy: 0.8553\n",
    "    Epoch 20/50\n",
    "    44800/44800 - 7s - loss: 0.5554 - accuracy: 0.8497 - val_loss: 0.6176 - val_accuracy: 0.8368\n",
    "    Epoch 21/50\n",
    "    44800/44800 - 7s - loss: 0.5203 - accuracy: 0.8545 - val_loss: 0.5572 - val_accuracy: 0.8153\n",
    "    Epoch 22/50\n",
    "    44800/44800 - 7s - loss: 0.5557 - accuracy: 0.8490 - val_loss: 0.5362 - val_accuracy: 0.8467\n",
    "    Epoch 23/50\n",
    "    44800/44800 - 7s - loss: 0.5413 - accuracy: 0.8573 - val_loss: 0.4858 - val_accuracy: 0.8728\n",
    "    Epoch 24/50\n",
    "    44800/44800 - 7s - loss: 0.5455 - accuracy: 0.8567 - val_loss: 0.6415 - val_accuracy: 0.8429\n",
    "    Epoch 25/50\n",
    "    44800/44800 - 7s - loss: 0.5278 - accuracy: 0.8618 - val_loss: 0.5093 - val_accuracy: 0.8704\n",
    "    Epoch 26/50\n",
    "    44800/44800 - 7s - loss: 0.5056 - accuracy: 0.8606 - val_loss: 0.6144 - val_accuracy: 0.8446\n",
    "    Epoch 27/50\n",
    "    44800/44800 - 7s - loss: 0.4808 - accuracy: 0.8757 - val_loss: 0.4533 - val_accuracy: 0.8815\n",
    "    Epoch 28/50\n",
    "    44800/44800 - 7s - loss: 0.5082 - accuracy: 0.8653 - val_loss: 0.5514 - val_accuracy: 0.8621\n",
    "    Epoch 29/50\n",
    "    44800/44800 - 7s - loss: 0.5235 - accuracy: 0.8606 - val_loss: 0.4918 - val_accuracy: 0.8768\n",
    "    Epoch 30/50\n",
    "    44800/44800 - 7s - loss: 0.4992 - accuracy: 0.8722 - val_loss: 0.5018 - val_accuracy: 0.8729\n",
    "    Epoch 31/50\n",
    "    44800/44800 - 7s - loss: 0.4938 - accuracy: 0.8687 - val_loss: 0.4629 - val_accuracy: 0.8822\n",
    "    Epoch 32/50\n",
    "    44800/44800 - 7s - loss: 0.5074 - accuracy: 0.8667 - val_loss: 0.4671 - val_accuracy: 0.8607\n",
    "    Epoch 33/50\n",
    "    44800/44800 - 7s - loss: 0.5286 - accuracy: 0.8597 - val_loss: 0.4884 - val_accuracy: 0.8599\n",
    "    Epoch 34/50\n",
    "    44800/44800 - 8s - loss: 0.5399 - accuracy: 0.8555 - val_loss: 0.5336 - val_accuracy: 0.8609\n",
    "    Epoch 35/50\n",
    "    44800/44800 - 8s - loss: 0.5077 - accuracy: 0.8661 - val_loss: 0.4685 - val_accuracy: 0.8759\n",
    "    Epoch 36/50\n",
    "    44800/44800 - 7s - loss: 0.5276 - accuracy: 0.8596 - val_loss: 0.4897 - val_accuracy: 0.8731\n",
    "    Epoch 37/50\n",
    "    44800/44800 - 7s - loss: 0.4790 - accuracy: 0.8738 - val_loss: 0.4413 - val_accuracy: 0.8777\n",
    "    Epoch 38/50\n",
    "    44800/44800 - 7s - loss: 0.4948 - accuracy: 0.8703 - val_loss: 0.6722 - val_accuracy: 0.8543\n",
    "    Epoch 39/50\n",
    "    44800/44800 - 7s - loss: 0.5118 - accuracy: 0.8637 - val_loss: 0.4232 - val_accuracy: 0.8964\n",
    "    Epoch 40/50\n",
    "    44800/44800 - 7s - loss: 0.5170 - accuracy: 0.8621 - val_loss: 0.4338 - val_accuracy: 0.8854\n",
    "    Epoch 41/50\n",
    "    44800/44800 - 7s - loss: 0.4608 - accuracy: 0.8798 - val_loss: 0.3878 - val_accuracy: 0.8975\n",
    "    Epoch 42/50\n",
    "    44800/44800 - 7s - loss: 0.4860 - accuracy: 0.8708 - val_loss: 0.4574 - val_accuracy: 0.8884\n",
    "    Epoch 43/50\n",
    "    44800/44800 - 7s - loss: 0.4839 - accuracy: 0.8754 - val_loss: 0.5732 - val_accuracy: 0.8547\n",
    "    Epoch 44/50\n",
    "    44800/44800 - 7s - loss: 0.4944 - accuracy: 0.8696 - val_loss: 0.5845 - val_accuracy: 0.8628\n",
    "    Epoch 45/50\n",
    "    44800/44800 - 7s - loss: 0.4828 - accuracy: 0.8766 - val_loss: 0.6316 - val_accuracy: 0.8579\n",
    "    Epoch 46/50\n",
    "    44800/44800 - 7s - loss: 0.4999 - accuracy: 0.8702 - val_loss: 0.5004 - val_accuracy: 0.8771\n",
    "    Epoch 47/50\n",
    "    44800/44800 - 7s - loss: 0.4837 - accuracy: 0.8760 - val_loss: 0.4608 - val_accuracy: 0.8861\n",
    "    Epoch 48/50\n",
    "    44800/44800 - 7s - loss: 0.4545 - accuracy: 0.8842 - val_loss: 0.5832 - val_accuracy: 0.8506\n",
    "    Epoch 49/50\n",
    "    44800/44800 - 7s - loss: 0.4863 - accuracy: 0.8737 - val_loss: 0.4036 - val_accuracy: 0.9029\n",
    "    Epoch 50/50\n",
    "    44800/44800 - 7s - loss: 0.4794 - accuracy: 0.8779 - val_loss: 0.4162 - val_accuracy: 0.8987"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using X_test\n",
    "y_pred = model.predict_classes(X_test)\n",
    "\n",
    "# Reshape predictions array (22800,1)\n",
    "y_pred = y_pred.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Y_Pred\n",
       "0       1\n",
       "1       2\n",
       "2       9\n",
       "3       8\n",
       "4       5"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert y_pred 1D Numpy Array to List\n",
    "y_pred = y_pred.tolist()\n",
    "\n",
    "# Flatten list of lists\n",
    "y_pred_flat = list(np.concatenate(y_pred))\n",
    "\n",
    "predictions = pd.DataFrame({\"Y_Pred\": y_pred_flat})\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11200/11200 [==============================] - 1s 70us/sample - loss: 0.4162 - accuracy: 0.8987\n",
      "Test accuracy: 89.866%\n"
     ]
    }
   ],
   "source": [
    "# evaluate test accuracy before train\n",
    "score = model.evaluate(X_val, Y_val, batch_size=32)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "# print test accuracy\n",
    "print('Test accuracy: %.3f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions to CSV file\n",
    "predictions.to_csv('Q4_prediction.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment with four optimizers: SGD, Adam, Momentum, and RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import CSVLogger\n",
    "callbacks = []\n",
    "\n",
    "# Create csv file to save model results\n",
    "log1 = CSVLogger('Adam_train_log.csv', append=True, separator=';')\n",
    "log2 = CSVLogger('SGD_train_log.csv', append=True, separator=';')\n",
    "log3 = CSVLogger('Momentum_train_log.csv', append=True, separator=';')\n",
    "log4 = CSVLogger('RMSprop_train_log.csv', append=True, separator=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 44800 samples, validate on 11200 samples\n",
      "Epoch 1/50\n",
      "44800/44800 [==============================] - 9s 206us/sample - loss: 0.4529 - accuracy: 0.8883 - val_loss: 0.5387 - val_accuracy: 0.8662\n",
      "Epoch 2/50\n",
      "44800/44800 [==============================] - 9s 197us/sample - loss: 0.4652 - accuracy: 0.8808 - val_loss: 0.4029 - val_accuracy: 0.9042\n",
      "Epoch 3/50\n",
      "44800/44800 [==============================] - 9s 193us/sample - loss: 0.4695 - accuracy: 0.8824 - val_loss: 0.4826 - val_accuracy: 0.8888\n",
      "Epoch 4/50\n",
      "44800/44800 [==============================] - 9s 192us/sample - loss: 0.4721 - accuracy: 0.8790 - val_loss: 0.5074 - val_accuracy: 0.8792\n",
      "Epoch 5/50\n",
      "44800/44800 [==============================] - 9s 190us/sample - loss: 0.4525 - accuracy: 0.8831 - val_loss: 0.4842 - val_accuracy: 0.8756\n",
      "Epoch 6/50\n",
      "44800/44800 [==============================] - 9s 190us/sample - loss: 0.4524 - accuracy: 0.8828 - val_loss: 0.7737 - val_accuracy: 0.8178\n",
      "Epoch 7/50\n",
      "44800/44800 [==============================] - 9s 193us/sample - loss: 0.4473 - accuracy: 0.8861 - val_loss: 0.4343 - val_accuracy: 0.8869\n",
      "Epoch 8/50\n",
      "44800/44800 [==============================] - 9s 191us/sample - loss: 0.4495 - accuracy: 0.8875 - val_loss: 0.4191 - val_accuracy: 0.9078\n",
      "Epoch 9/50\n",
      "44800/44800 [==============================] - 9s 190us/sample - loss: 0.4422 - accuracy: 0.8899 - val_loss: 0.4815 - val_accuracy: 0.8824\n",
      "Epoch 10/50\n",
      "44800/44800 [==============================] - 9s 191us/sample - loss: 0.4434 - accuracy: 0.8861 - val_loss: 0.3783 - val_accuracy: 0.9089\n",
      "Epoch 11/50\n",
      "44800/44800 [==============================] - 9s 191us/sample - loss: 0.4603 - accuracy: 0.8811 - val_loss: 0.4880 - val_accuracy: 0.8818\n",
      "Epoch 12/50\n",
      "44800/44800 [==============================] - 9s 191us/sample - loss: 0.4483 - accuracy: 0.8871 - val_loss: 0.4666 - val_accuracy: 0.8841\n",
      "Epoch 13/50\n",
      "44800/44800 [==============================] - 9s 191us/sample - loss: 0.4664 - accuracy: 0.8793 - val_loss: 0.4819 - val_accuracy: 0.8766\n",
      "Epoch 14/50\n",
      "44800/44800 [==============================] - 9s 191us/sample - loss: 0.4341 - accuracy: 0.8907 - val_loss: 0.7004 - val_accuracy: 0.8495\n",
      "Epoch 15/50\n",
      "44800/44800 [==============================] - 9s 208us/sample - loss: 0.4380 - accuracy: 0.8910 - val_loss: 0.4883 - val_accuracy: 0.8887\n",
      "Epoch 16/50\n",
      "44800/44800 [==============================] - 9s 191us/sample - loss: 0.4692 - accuracy: 0.8799 - val_loss: 0.5770 - val_accuracy: 0.8537\n",
      "Epoch 17/50\n",
      "44800/44800 [==============================] - 9s 192us/sample - loss: 0.4326 - accuracy: 0.8912 - val_loss: 0.4469 - val_accuracy: 0.8965\n",
      "Epoch 18/50\n",
      "44800/44800 [==============================] - 9s 192us/sample - loss: 0.4397 - accuracy: 0.8862 - val_loss: 0.5827 - val_accuracy: 0.8261\n",
      "Epoch 19/50\n",
      "44800/44800 [==============================] - 9s 197us/sample - loss: 0.4469 - accuracy: 0.8804 - val_loss: 0.4207 - val_accuracy: 0.8862\n",
      "Epoch 20/50\n",
      "44800/44800 [==============================] - 9s 195us/sample - loss: 0.4433 - accuracy: 0.8875 - val_loss: 0.4632 - val_accuracy: 0.8918\n",
      "Epoch 21/50\n",
      "44800/44800 [==============================] - 9s 193us/sample - loss: 0.4618 - accuracy: 0.8847 - val_loss: 0.4658 - val_accuracy: 0.8892\n",
      "Epoch 22/50\n",
      "44800/44800 [==============================] - 10s 219us/sample - loss: 0.4496 - accuracy: 0.8843 - val_loss: 0.4628 - val_accuracy: 0.8961\n",
      "Epoch 23/50\n",
      "44800/44800 [==============================] - 9s 193us/sample - loss: 0.4339 - accuracy: 0.8910 - val_loss: 0.5191 - val_accuracy: 0.8647\n",
      "Epoch 24/50\n",
      "44800/44800 [==============================] - 9s 195us/sample - loss: 0.4273 - accuracy: 0.8898 - val_loss: 0.4285 - val_accuracy: 0.9053\n",
      "Epoch 25/50\n",
      "44800/44800 [==============================] - 9s 204us/sample - loss: 0.4295 - accuracy: 0.8902 - val_loss: 0.4150 - val_accuracy: 0.9003\n",
      "Epoch 26/50\n",
      "44800/44800 [==============================] - 9s 193us/sample - loss: 0.3930 - accuracy: 0.9041 - val_loss: 0.3693 - val_accuracy: 0.9113\n",
      "Epoch 27/50\n",
      "44800/44800 [==============================] - 9s 191us/sample - loss: 0.4259 - accuracy: 0.8913 - val_loss: 0.5109 - val_accuracy: 0.8699\n",
      "Epoch 28/50\n",
      "44800/44800 [==============================] - 9s 199us/sample - loss: 0.4343 - accuracy: 0.8908 - val_loss: 0.4955 - val_accuracy: 0.8832\n",
      "Epoch 29/50\n",
      "44800/44800 [==============================] - 9s 197us/sample - loss: 0.4327 - accuracy: 0.8908 - val_loss: 0.3885 - val_accuracy: 0.9021\n",
      "Epoch 30/50\n",
      "44800/44800 [==============================] - 9s 195us/sample - loss: 0.4463 - accuracy: 0.8885 - val_loss: 0.4588 - val_accuracy: 0.8955\n",
      "Epoch 31/50\n",
      "44800/44800 [==============================] - 9s 197us/sample - loss: 0.4382 - accuracy: 0.8878 - val_loss: 0.4110 - val_accuracy: 0.8893\n",
      "Epoch 32/50\n",
      "44800/44800 [==============================] - 9s 196us/sample - loss: 0.4416 - accuracy: 0.8871 - val_loss: 0.3825 - val_accuracy: 0.9081\n",
      "Epoch 33/50\n",
      "44800/44800 [==============================] - 9s 196us/sample - loss: 0.4414 - accuracy: 0.8880 - val_loss: 0.4411 - val_accuracy: 0.8788\n",
      "Epoch 34/50\n",
      "44800/44800 [==============================] - 9s 195us/sample - loss: 0.4360 - accuracy: 0.8893 - val_loss: 0.3846 - val_accuracy: 0.9026\n",
      "Epoch 35/50\n",
      "44800/44800 [==============================] - 9s 197us/sample - loss: 0.4346 - accuracy: 0.8892 - val_loss: 0.3324 - val_accuracy: 0.9208\n",
      "Epoch 36/50\n",
      "44800/44800 [==============================] - 9s 196us/sample - loss: 0.4199 - accuracy: 0.8932 - val_loss: 0.6095 - val_accuracy: 0.8513\n",
      "Epoch 37/50\n",
      "44800/44800 [==============================] - 9s 193us/sample - loss: 0.4248 - accuracy: 0.8906 - val_loss: 0.4680 - val_accuracy: 0.8854\n",
      "Epoch 38/50\n",
      "44800/44800 [==============================] - 9s 196us/sample - loss: 0.4375 - accuracy: 0.8918 - val_loss: 0.4804 - val_accuracy: 0.8888\n",
      "Epoch 39/50\n",
      "44800/44800 [==============================] - 9s 199us/sample - loss: 0.4132 - accuracy: 0.8949 - val_loss: 0.4092 - val_accuracy: 0.8998\n",
      "Epoch 40/50\n",
      "44800/44800 [==============================] - 9s 197us/sample - loss: 0.4269 - accuracy: 0.8915 - val_loss: 0.4829 - val_accuracy: 0.8856\n",
      "Epoch 41/50\n",
      "44800/44800 [==============================] - 9s 197us/sample - loss: 0.4191 - accuracy: 0.8962 - val_loss: 0.3498 - val_accuracy: 0.9064\n",
      "Epoch 42/50\n",
      "44800/44800 [==============================] - 9s 198us/sample - loss: 0.4357 - accuracy: 0.8883 - val_loss: 0.3975 - val_accuracy: 0.9025\n",
      "Epoch 43/50\n",
      "44800/44800 [==============================] - 9s 195us/sample - loss: 0.4005 - accuracy: 0.8985 - val_loss: 0.4080 - val_accuracy: 0.9001\n",
      "Epoch 44/50\n",
      "44800/44800 [==============================] - 9s 198us/sample - loss: 0.4076 - accuracy: 0.8976 - val_loss: 0.4393 - val_accuracy: 0.8951\n",
      "Epoch 45/50\n",
      "44800/44800 [==============================] - 9s 197us/sample - loss: 0.4133 - accuracy: 0.8966 - val_loss: 0.3356 - val_accuracy: 0.9077\n",
      "Epoch 46/50\n",
      "44800/44800 [==============================] - 9s 196us/sample - loss: 0.4101 - accuracy: 0.9011 - val_loss: 0.3854 - val_accuracy: 0.9064\n",
      "Epoch 47/50\n",
      "44800/44800 [==============================] - 9s 197us/sample - loss: 0.4036 - accuracy: 0.8981 - val_loss: 0.6845 - val_accuracy: 0.8427\n",
      "Epoch 48/50\n",
      "44800/44800 [==============================] - 9s 196us/sample - loss: 0.4036 - accuracy: 0.8977 - val_loss: 0.4339 - val_accuracy: 0.8914\n",
      "Epoch 49/50\n",
      "44800/44800 [==============================] - 9s 192us/sample - loss: 0.4187 - accuracy: 0.8987 - val_loss: 0.3704 - val_accuracy: 0.9017\n",
      "Epoch 50/50\n",
      "44800/44800 [==============================] - 9s 211us/sample - loss: 0.4095 - accuracy: 0.8957 - val_loss: 0.4828 - val_accuracy: 0.8929\n",
      "Time:  439.243390179\n"
     ]
    }
   ],
   "source": [
    "#1) Adam\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Start running time\n",
    "start = timeit.default_timer()\n",
    "\n",
    "# Train the model for 50 epochs using Adam optimizer\n",
    "adam_metrics = model.fit(X_train, Y_train, batch_size=32, epochs=50, validation_data=(X_val, Y_val), callbacks=[log1])\n",
    "\n",
    "callbacks.append(CSVLogger(log1))\n",
    "\n",
    "# Stop running time\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print(\"Time: \", stop - start) #Time:  404.5758666740003s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam Optimizer Performance Metrics:\n",
    "\n",
    "* Overall validation accuracy: 0.9144\n",
    "* Test accuracy: 0.8938\n",
    "* Training time: 6.7 mins\n",
    "* Training loss: 0.4053\n",
    "* Validation loss: 0.3349"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 44800 samples, validate on 11200 samples\n",
      "Epoch 1/50\n",
      "44800/44800 [==============================] - 8s 169us/sample - loss: 0.3147 - accuracy: 0.9174 - val_loss: 0.3357 - val_accuracy: 0.9109\n",
      "Epoch 2/50\n",
      "44800/44800 [==============================] - 7s 162us/sample - loss: 0.3021 - accuracy: 0.9195 - val_loss: 0.3310 - val_accuracy: 0.9131\n",
      "Epoch 3/50\n",
      "44800/44800 [==============================] - 7s 167us/sample - loss: 0.2948 - accuracy: 0.9212 - val_loss: 0.3220 - val_accuracy: 0.9145\n",
      "Epoch 4/50\n",
      "44800/44800 [==============================] - 7s 163us/sample - loss: 0.2891 - accuracy: 0.9225 - val_loss: 0.3210 - val_accuracy: 0.9134\n",
      "Epoch 5/50\n",
      "44800/44800 [==============================] - 7s 166us/sample - loss: 0.2846 - accuracy: 0.9227 - val_loss: 0.3148 - val_accuracy: 0.9139\n",
      "Epoch 6/50\n",
      "44800/44800 [==============================] - 8s 170us/sample - loss: 0.2809 - accuracy: 0.9227 - val_loss: 0.3126 - val_accuracy: 0.9143\n",
      "Epoch 7/50\n",
      "44800/44800 [==============================] - 8s 178us/sample - loss: 0.2772 - accuracy: 0.9239 - val_loss: 0.3098 - val_accuracy: 0.9128\n",
      "Epoch 8/50\n",
      "44800/44800 [==============================] - 9s 190us/sample - loss: 0.2746 - accuracy: 0.9245 - val_loss: 0.3073 - val_accuracy: 0.9153\n",
      "Epoch 9/50\n",
      "44800/44800 [==============================] - 8s 168us/sample - loss: 0.2719 - accuracy: 0.9246 - val_loss: 0.3036 - val_accuracy: 0.9139\n",
      "Epoch 10/50\n",
      "44800/44800 [==============================] - 8s 175us/sample - loss: 0.2697 - accuracy: 0.9247 - val_loss: 0.3025 - val_accuracy: 0.9148\n",
      "Epoch 11/50\n",
      "44800/44800 [==============================] - 7s 164us/sample - loss: 0.2677 - accuracy: 0.9246 - val_loss: 0.3026 - val_accuracy: 0.9141\n",
      "Epoch 12/50\n",
      "44800/44800 [==============================] - 7s 165us/sample - loss: 0.2660 - accuracy: 0.9252 - val_loss: 0.2983 - val_accuracy: 0.9144\n",
      "Epoch 13/50\n",
      "44800/44800 [==============================] - 7s 165us/sample - loss: 0.2645 - accuracy: 0.9253 - val_loss: 0.2972 - val_accuracy: 0.9148\n",
      "Epoch 14/50\n",
      "44800/44800 [==============================] - 7s 164us/sample - loss: 0.2635 - accuracy: 0.9262 - val_loss: 0.2969 - val_accuracy: 0.9150\n",
      "Epoch 15/50\n",
      "44800/44800 [==============================] - 7s 162us/sample - loss: 0.2621 - accuracy: 0.9253 - val_loss: 0.2984 - val_accuracy: 0.9163\n",
      "Epoch 16/50\n",
      "44800/44800 [==============================] - 7s 165us/sample - loss: 0.2606 - accuracy: 0.9257 - val_loss: 0.2958 - val_accuracy: 0.9154\n",
      "Epoch 17/50\n",
      "44800/44800 [==============================] - 7s 164us/sample - loss: 0.2596 - accuracy: 0.9264 - val_loss: 0.2935 - val_accuracy: 0.9162\n",
      "Epoch 18/50\n",
      "44800/44800 [==============================] - 7s 165us/sample - loss: 0.2586 - accuracy: 0.9260 - val_loss: 0.2961 - val_accuracy: 0.9164\n",
      "Epoch 19/50\n",
      "44800/44800 [==============================] - 7s 165us/sample - loss: 0.2578 - accuracy: 0.9261 - val_loss: 0.2911 - val_accuracy: 0.9150\n",
      "Epoch 20/50\n",
      "44800/44800 [==============================] - 8s 168us/sample - loss: 0.2567 - accuracy: 0.9266 - val_loss: 0.2948 - val_accuracy: 0.9153\n",
      "Epoch 21/50\n",
      "44800/44800 [==============================] - 8s 168us/sample - loss: 0.2562 - accuracy: 0.9270 - val_loss: 0.2915 - val_accuracy: 0.9166\n",
      "Epoch 22/50\n",
      "44800/44800 [==============================] - 8s 168us/sample - loss: 0.2554 - accuracy: 0.9266 - val_loss: 0.2901 - val_accuracy: 0.9152\n",
      "Epoch 23/50\n",
      "44800/44800 [==============================] - 7s 165us/sample - loss: 0.2548 - accuracy: 0.9265 - val_loss: 0.2900 - val_accuracy: 0.9148\n",
      "Epoch 24/50\n",
      "44800/44800 [==============================] - 7s 161us/sample - loss: 0.2544 - accuracy: 0.9267 - val_loss: 0.2910 - val_accuracy: 0.9165\n",
      "Epoch 25/50\n",
      "44800/44800 [==============================] - 7s 162us/sample - loss: 0.2538 - accuracy: 0.9273 - val_loss: 0.2886 - val_accuracy: 0.9154\n",
      "Epoch 26/50\n",
      "44800/44800 [==============================] - 7s 161us/sample - loss: 0.2532 - accuracy: 0.9274 - val_loss: 0.2881 - val_accuracy: 0.9160\n",
      "Epoch 27/50\n",
      "44800/44800 [==============================] - 7s 159us/sample - loss: 0.2529 - accuracy: 0.9270 - val_loss: 0.2888 - val_accuracy: 0.9171\n",
      "Epoch 28/50\n",
      "44800/44800 [==============================] - 7s 159us/sample - loss: 0.2525 - accuracy: 0.9274 - val_loss: 0.2865 - val_accuracy: 0.9163\n",
      "Epoch 29/50\n",
      "44800/44800 [==============================] - 7s 164us/sample - loss: 0.2517 - accuracy: 0.9275 - val_loss: 0.2863 - val_accuracy: 0.9161\n",
      "Epoch 30/50\n",
      "44800/44800 [==============================] - 7s 162us/sample - loss: 0.2514 - accuracy: 0.9277 - val_loss: 0.2865 - val_accuracy: 0.9156\n",
      "Epoch 31/50\n",
      "44800/44800 [==============================] - 7s 161us/sample - loss: 0.2508 - accuracy: 0.9276 - val_loss: 0.2869 - val_accuracy: 0.9146\n",
      "Epoch 32/50\n",
      "44800/44800 [==============================] - 7s 161us/sample - loss: 0.2506 - accuracy: 0.9281 - val_loss: 0.2857 - val_accuracy: 0.9162\n",
      "Epoch 33/50\n",
      "44800/44800 [==============================] - 7s 162us/sample - loss: 0.2502 - accuracy: 0.9276 - val_loss: 0.2878 - val_accuracy: 0.9162\n",
      "Epoch 34/50\n",
      "44800/44800 [==============================] - 7s 161us/sample - loss: 0.2496 - accuracy: 0.9280 - val_loss: 0.2864 - val_accuracy: 0.9146\n",
      "Epoch 35/50\n",
      "44800/44800 [==============================] - 7s 160us/sample - loss: 0.2496 - accuracy: 0.9288 - val_loss: 0.2855 - val_accuracy: 0.9158\n",
      "Epoch 36/50\n",
      "44800/44800 [==============================] - 7s 164us/sample - loss: 0.2494 - accuracy: 0.9282 - val_loss: 0.2837 - val_accuracy: 0.9158\n",
      "Epoch 37/50\n",
      "44800/44800 [==============================] - 8s 169us/sample - loss: 0.2490 - accuracy: 0.9277 - val_loss: 0.2839 - val_accuracy: 0.9162\n",
      "Epoch 38/50\n",
      "44800/44800 [==============================] - 8s 168us/sample - loss: 0.2483 - accuracy: 0.9276 - val_loss: 0.2848 - val_accuracy: 0.9173\n",
      "Epoch 39/50\n",
      "44800/44800 [==============================] - 7s 167us/sample - loss: 0.2483 - accuracy: 0.9285 - val_loss: 0.2851 - val_accuracy: 0.9162\n",
      "Epoch 40/50\n",
      "44800/44800 [==============================] - 8s 186us/sample - loss: 0.2480 - accuracy: 0.9285 - val_loss: 0.2845 - val_accuracy: 0.9151\n",
      "Epoch 41/50\n",
      "44800/44800 [==============================] - 8s 173us/sample - loss: 0.2479 - accuracy: 0.9284 - val_loss: 0.2820 - val_accuracy: 0.9162\n",
      "Epoch 42/50\n",
      "44800/44800 [==============================] - 7s 165us/sample - loss: 0.2477 - accuracy: 0.9286 - val_loss: 0.2839 - val_accuracy: 0.9175\n",
      "Epoch 43/50\n",
      "44800/44800 [==============================] - 8s 169us/sample - loss: 0.2472 - accuracy: 0.9287 - val_loss: 0.2824 - val_accuracy: 0.9166\n",
      "Epoch 44/50\n",
      "44800/44800 [==============================] - 8s 176us/sample - loss: 0.2472 - accuracy: 0.9283 - val_loss: 0.2835 - val_accuracy: 0.9151\n",
      "Epoch 45/50\n",
      "44800/44800 [==============================] - 8s 174us/sample - loss: 0.2469 - accuracy: 0.9295 - val_loss: 0.2831 - val_accuracy: 0.9169\n",
      "Epoch 46/50\n",
      "44800/44800 [==============================] - 8s 168us/sample - loss: 0.2469 - accuracy: 0.9289 - val_loss: 0.2815 - val_accuracy: 0.9159\n",
      "Epoch 47/50\n",
      "44800/44800 [==============================] - 8s 169us/sample - loss: 0.2466 - accuracy: 0.9287 - val_loss: 0.2834 - val_accuracy: 0.9168\n",
      "Epoch 48/50\n",
      "44800/44800 [==============================] - 8s 172us/sample - loss: 0.2460 - accuracy: 0.9290 - val_loss: 0.2812 - val_accuracy: 0.9161\n",
      "Epoch 49/50\n",
      "44800/44800 [==============================] - 9s 193us/sample - loss: 0.2459 - accuracy: 0.9291 - val_loss: 0.2807 - val_accuracy: 0.9168\n",
      "Epoch 50/50\n",
      "44800/44800 [==============================] - 9s 200us/sample - loss: 0.2459 - accuracy: 0.9284 - val_loss: 0.2823 - val_accuracy: 0.9173\n",
      "Time:  376.7197854700007\n"
     ]
    }
   ],
   "source": [
    "#2) SGD\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.0), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Start running time\n",
    "start = timeit.default_timer()\n",
    "\n",
    "# Train the model for 50 epochs using SGD optimizer\n",
    "sgd_metrics = model.fit(X_train, Y_train, batch_size=32, epochs=50, validation_data=(X_val, Y_val), callbacks=[log2])\n",
    "\n",
    "callbacks.append(CSVLogger(log2))\n",
    "\n",
    "# Stop running time\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print(\"Time: \", stop - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Optimizer Performance Metrics:\n",
    "\n",
    "* Overall validation accuracy: 0.8987\n",
    "* Test accuracy: 0.8779\n",
    "* Training time: 9.3 mins\n",
    "* Training loss: 0.4794\n",
    "* Validation loss: 0.4162"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 44800 samples, validate on 11200 samples\n",
      "Epoch 1/50\n",
      "44800/44800 [==============================] - 8s 189us/sample - loss: 0.2557 - accuracy: 0.9269 - val_loss: 0.2918 - val_accuracy: 0.9162\n",
      "Epoch 2/50\n",
      "44800/44800 [==============================] - 8s 188us/sample - loss: 0.2537 - accuracy: 0.9269 - val_loss: 0.2845 - val_accuracy: 0.9182\n",
      "Epoch 3/50\n",
      "44800/44800 [==============================] - 8s 184us/sample - loss: 0.2533 - accuracy: 0.9280 - val_loss: 0.2978 - val_accuracy: 0.9143\n",
      "Epoch 4/50\n",
      "44800/44800 [==============================] - 9s 212us/sample - loss: 0.2533 - accuracy: 0.9271 - val_loss: 0.2844 - val_accuracy: 0.9155\n",
      "Epoch 5/50\n",
      "44800/44800 [==============================] - 10s 218us/sample - loss: 0.2505 - accuracy: 0.9277 - val_loss: 0.2862 - val_accuracy: 0.9168\n",
      "Epoch 6/50\n",
      "44800/44800 [==============================] - 10s 223us/sample - loss: 0.2501 - accuracy: 0.9283 - val_loss: 0.2842 - val_accuracy: 0.9179\n",
      "Epoch 7/50\n",
      "44800/44800 [==============================] - 10s 217us/sample - loss: 0.2491 - accuracy: 0.9288 - val_loss: 0.2791 - val_accuracy: 0.9171\n",
      "Epoch 8/50\n",
      "44800/44800 [==============================] - 10s 221us/sample - loss: 0.2494 - accuracy: 0.9287 - val_loss: 0.2851 - val_accuracy: 0.9198\n",
      "Epoch 9/50\n",
      "44800/44800 [==============================] - 10s 212us/sample - loss: 0.2479 - accuracy: 0.9285 - val_loss: 0.2851 - val_accuracy: 0.9170\n",
      "Epoch 10/50\n",
      "44800/44800 [==============================] - 9s 211us/sample - loss: 0.2477 - accuracy: 0.9289 - val_loss: 0.2835 - val_accuracy: 0.9171\n",
      "Epoch 11/50\n",
      "44800/44800 [==============================] - 9s 207us/sample - loss: 0.2468 - accuracy: 0.9293 - val_loss: 0.2823 - val_accuracy: 0.9181\n",
      "Epoch 12/50\n",
      "44800/44800 [==============================] - 9s 198us/sample - loss: 0.2454 - accuracy: 0.9291 - val_loss: 0.2862 - val_accuracy: 0.9187\n",
      "Epoch 13/50\n",
      "44800/44800 [==============================] - 9s 194us/sample - loss: 0.2461 - accuracy: 0.9297 - val_loss: 0.2800 - val_accuracy: 0.9198\n",
      "Epoch 14/50\n",
      "44800/44800 [==============================] - 9s 199us/sample - loss: 0.2445 - accuracy: 0.9303 - val_loss: 0.2847 - val_accuracy: 0.9183\n",
      "Epoch 15/50\n",
      "44800/44800 [==============================] - 9s 209us/sample - loss: 0.2437 - accuracy: 0.9296 - val_loss: 0.2783 - val_accuracy: 0.9207\n",
      "Epoch 16/50\n",
      "44800/44800 [==============================] - 10s 215us/sample - loss: 0.2431 - accuracy: 0.9308 - val_loss: 0.2861 - val_accuracy: 0.9167\n",
      "Epoch 17/50\n",
      "44800/44800 [==============================] - 9s 211us/sample - loss: 0.2435 - accuracy: 0.9309 - val_loss: 0.2851 - val_accuracy: 0.9182\n",
      "Epoch 18/50\n",
      "44800/44800 [==============================] - 9s 207us/sample - loss: 0.2426 - accuracy: 0.9313 - val_loss: 0.2877 - val_accuracy: 0.9154\n",
      "Epoch 19/50\n",
      "44800/44800 [==============================] - 8s 181us/sample - loss: 0.2436 - accuracy: 0.9302 - val_loss: 0.2837 - val_accuracy: 0.9177\n",
      "Epoch 20/50\n",
      "44800/44800 [==============================] - 8s 179us/sample - loss: 0.2424 - accuracy: 0.9308 - val_loss: 0.2788 - val_accuracy: 0.9175\n",
      "Epoch 21/50\n",
      "44800/44800 [==============================] - 8s 185us/sample - loss: 0.2409 - accuracy: 0.9307 - val_loss: 0.2808 - val_accuracy: 0.9208\n",
      "Epoch 22/50\n",
      "44800/44800 [==============================] - 8s 185us/sample - loss: 0.2404 - accuracy: 0.9308 - val_loss: 0.2817 - val_accuracy: 0.9209\n",
      "Epoch 23/50\n",
      "44800/44800 [==============================] - 8s 184us/sample - loss: 0.2408 - accuracy: 0.9315 - val_loss: 0.2849 - val_accuracy: 0.9172\n",
      "Epoch 24/50\n",
      "44800/44800 [==============================] - 8s 183us/sample - loss: 0.2395 - accuracy: 0.9318 - val_loss: 0.2823 - val_accuracy: 0.9188\n",
      "Epoch 25/50\n",
      "44800/44800 [==============================] - 9s 190us/sample - loss: 0.2403 - accuracy: 0.9312 - val_loss: 0.2774 - val_accuracy: 0.9188\n",
      "Epoch 26/50\n",
      "44800/44800 [==============================] - 8s 184us/sample - loss: 0.2388 - accuracy: 0.9322 - val_loss: 0.2872 - val_accuracy: 0.9170\n",
      "Epoch 27/50\n",
      "44800/44800 [==============================] - 8s 179us/sample - loss: 0.2386 - accuracy: 0.9322 - val_loss: 0.2847 - val_accuracy: 0.9172\n",
      "Epoch 28/50\n",
      "44800/44800 [==============================] - 8s 178us/sample - loss: 0.2382 - accuracy: 0.9316 - val_loss: 0.2855 - val_accuracy: 0.9184\n",
      "Epoch 29/50\n",
      "44800/44800 [==============================] - 8s 179us/sample - loss: 0.2378 - accuracy: 0.9325 - val_loss: 0.2837 - val_accuracy: 0.9156\n",
      "Epoch 30/50\n",
      "44800/44800 [==============================] - 8s 177us/sample - loss: 0.2375 - accuracy: 0.9323 - val_loss: 0.2854 - val_accuracy: 0.9179\n",
      "Epoch 31/50\n",
      "44800/44800 [==============================] - 8s 176us/sample - loss: 0.2375 - accuracy: 0.9321 - val_loss: 0.2767 - val_accuracy: 0.9196\n",
      "Epoch 32/50\n",
      "44800/44800 [==============================] - 8s 178us/sample - loss: 0.2370 - accuracy: 0.9317 - val_loss: 0.2806 - val_accuracy: 0.9183\n",
      "Epoch 33/50\n",
      "44800/44800 [==============================] - 8s 178us/sample - loss: 0.2365 - accuracy: 0.9324 - val_loss: 0.2896 - val_accuracy: 0.9183\n",
      "Epoch 34/50\n",
      "44800/44800 [==============================] - 9s 190us/sample - loss: 0.2371 - accuracy: 0.9324 - val_loss: 0.2773 - val_accuracy: 0.9203\n",
      "Epoch 35/50\n",
      "44800/44800 [==============================] - 9s 201us/sample - loss: 0.2355 - accuracy: 0.9323 - val_loss: 0.2852 - val_accuracy: 0.9196\n",
      "Epoch 36/50\n",
      "44800/44800 [==============================] - 8s 179us/sample - loss: 0.2359 - accuracy: 0.9327 - val_loss: 0.2737 - val_accuracy: 0.9197\n",
      "Epoch 37/50\n",
      "44800/44800 [==============================] - 8s 178us/sample - loss: 0.2358 - accuracy: 0.9325 - val_loss: 0.2808 - val_accuracy: 0.9216\n",
      "Epoch 38/50\n",
      "44800/44800 [==============================] - 8s 176us/sample - loss: 0.2351 - accuracy: 0.9341 - val_loss: 0.2831 - val_accuracy: 0.9198\n",
      "Epoch 39/50\n",
      "44800/44800 [==============================] - 8s 174us/sample - loss: 0.2351 - accuracy: 0.9323 - val_loss: 0.2773 - val_accuracy: 0.9197\n",
      "Epoch 40/50\n",
      "44800/44800 [==============================] - 8s 177us/sample - loss: 0.2361 - accuracy: 0.9329 - val_loss: 0.2790 - val_accuracy: 0.9203\n",
      "Epoch 41/50\n",
      "44800/44800 [==============================] - 8s 174us/sample - loss: 0.2347 - accuracy: 0.9331 - val_loss: 0.2752 - val_accuracy: 0.9217\n",
      "Epoch 42/50\n",
      "44800/44800 [==============================] - 8s 173us/sample - loss: 0.2345 - accuracy: 0.9326 - val_loss: 0.2739 - val_accuracy: 0.9223\n",
      "Epoch 43/50\n",
      "44800/44800 [==============================] - 8s 173us/sample - loss: 0.2355 - accuracy: 0.9336 - val_loss: 0.2786 - val_accuracy: 0.9204\n",
      "Epoch 44/50\n",
      "44800/44800 [==============================] - 8s 173us/sample - loss: 0.2351 - accuracy: 0.9325 - val_loss: 0.2819 - val_accuracy: 0.9183\n",
      "Epoch 45/50\n",
      "44800/44800 [==============================] - 8s 174us/sample - loss: 0.2340 - accuracy: 0.9338 - val_loss: 0.2779 - val_accuracy: 0.9213\n",
      "Epoch 46/50\n",
      "44800/44800 [==============================] - 8s 173us/sample - loss: 0.2347 - accuracy: 0.9332 - val_loss: 0.2798 - val_accuracy: 0.9203\n",
      "Epoch 47/50\n",
      "44800/44800 [==============================] - 8s 175us/sample - loss: 0.2336 - accuracy: 0.9333 - val_loss: 0.2863 - val_accuracy: 0.9199\n",
      "Epoch 48/50\n",
      "44800/44800 [==============================] - 8s 174us/sample - loss: 0.2351 - accuracy: 0.9333 - val_loss: 0.2806 - val_accuracy: 0.9195\n",
      "Epoch 49/50\n",
      "44800/44800 [==============================] - 8s 175us/sample - loss: 0.2335 - accuracy: 0.9334 - val_loss: 0.2884 - val_accuracy: 0.9158\n",
      "Epoch 50/50\n",
      "44800/44800 [==============================] - 8s 178us/sample - loss: 0.2338 - accuracy: 0.9328 - val_loss: 0.2842 - val_accuracy: 0.9196\n",
      "Time:  423.64112346\n"
     ]
    }
   ],
   "source": [
    "#3) Momentum\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.8), loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# Start running time\n",
    "start = timeit.default_timer()\n",
    "\n",
    "# Train the model for 50 epochs using SGD Momentum =  0.8\n",
    "momentum_metrics = model.fit(X_train, Y_train, batch_size=32, epochs=50, validation_data=(X_val, Y_val), callbacks=[log3])\n",
    "\n",
    "callbacks.append(CSVLogger(log3))\n",
    "\n",
    "# Stop running time\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print(\"Time: \", stop - start) # Time:  363.1876358380032s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum Optimizer Performance Metrics:\n",
    "\n",
    "* Overall validation accuracy: 0.9804\n",
    "* Test accuracy: 1.0000\n",
    "* Training time: 6.1 mins\n",
    "* Training loss: 0.0019\n",
    "* Validation loss: 0.0751"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 44800 samples, validate on 11200 samples\n",
      "Epoch 1/50\n",
      "44800/44800 [==============================] - 11s 240us/sample - loss: 0.4042 - accuracy: 0.9110 - val_loss: 0.3487 - val_accuracy: 0.9338\n",
      "Epoch 2/50\n",
      "44800/44800 [==============================] - 11s 236us/sample - loss: 0.3971 - accuracy: 0.9166 - val_loss: 0.3861 - val_accuracy: 0.9241\n",
      "Epoch 3/50\n",
      "44800/44800 [==============================] - 11s 235us/sample - loss: 0.3953 - accuracy: 0.9225 - val_loss: 0.3389 - val_accuracy: 0.9330\n",
      "Epoch 4/50\n",
      "44800/44800 [==============================] - 11s 235us/sample - loss: 0.3757 - accuracy: 0.9246 - val_loss: 0.3593 - val_accuracy: 0.9308\n",
      "Epoch 5/50\n",
      "44800/44800 [==============================] - 11s 234us/sample - loss: 0.3777 - accuracy: 0.9252 - val_loss: 0.4089 - val_accuracy: 0.9226\n",
      "Epoch 6/50\n",
      "44800/44800 [==============================] - 11s 237us/sample - loss: 0.3666 - accuracy: 0.9289 - val_loss: 0.3629 - val_accuracy: 0.9341\n",
      "Epoch 7/50\n",
      "44800/44800 [==============================] - 10s 234us/sample - loss: 0.3668 - accuracy: 0.9304 - val_loss: 0.3230 - val_accuracy: 0.9409\n",
      "Epoch 8/50\n",
      "44800/44800 [==============================] - 11s 235us/sample - loss: 0.3683 - accuracy: 0.9285 - val_loss: 0.3517 - val_accuracy: 0.9334\n",
      "Epoch 9/50\n",
      "44800/44800 [==============================] - 10s 234us/sample - loss: 0.3508 - accuracy: 0.9331 - val_loss: 0.3331 - val_accuracy: 0.9373\n",
      "Epoch 10/50\n",
      "44800/44800 [==============================] - 11s 249us/sample - loss: 0.3607 - accuracy: 0.9311 - val_loss: 0.3245 - val_accuracy: 0.9423\n",
      "Epoch 11/50\n",
      "44800/44800 [==============================] - 10s 234us/sample - loss: 0.3455 - accuracy: 0.9350 - val_loss: 0.4069 - val_accuracy: 0.9303\n",
      "Epoch 12/50\n",
      "44800/44800 [==============================] - 10s 234us/sample - loss: 0.3418 - accuracy: 0.9358 - val_loss: 0.4953 - val_accuracy: 0.8817\n",
      "Epoch 13/50\n",
      "44800/44800 [==============================] - 10s 234us/sample - loss: 0.3356 - accuracy: 0.9364 - val_loss: 0.3334 - val_accuracy: 0.9416\n",
      "Epoch 14/50\n",
      "44800/44800 [==============================] - 10s 234us/sample - loss: 0.3358 - accuracy: 0.9372 - val_loss: 0.3825 - val_accuracy: 0.9351\n",
      "Epoch 15/50\n",
      "44800/44800 [==============================] - 10s 234us/sample - loss: 0.3280 - accuracy: 0.9385 - val_loss: 0.3328 - val_accuracy: 0.9381\n",
      "Epoch 16/50\n",
      "44800/44800 [==============================] - 10s 233us/sample - loss: 0.3171 - accuracy: 0.9404 - val_loss: 0.3903 - val_accuracy: 0.9222\n",
      "Epoch 17/50\n",
      "44800/44800 [==============================] - 11s 256us/sample - loss: 0.3306 - accuracy: 0.9379 - val_loss: 0.3418 - val_accuracy: 0.9417\n",
      "Epoch 18/50\n",
      "44800/44800 [==============================] - 11s 246us/sample - loss: 0.3262 - accuracy: 0.9398 - val_loss: 0.3121 - val_accuracy: 0.9457\n",
      "Epoch 19/50\n",
      "44800/44800 [==============================] - 10s 233us/sample - loss: 0.3219 - accuracy: 0.9395 - val_loss: 0.3902 - val_accuracy: 0.9314\n",
      "Epoch 20/50\n",
      "44800/44800 [==============================] - 11s 235us/sample - loss: 0.3266 - accuracy: 0.9388 - val_loss: 0.3997 - val_accuracy: 0.9309\n",
      "Epoch 21/50\n",
      "44800/44800 [==============================] - 11s 235us/sample - loss: 0.3158 - accuracy: 0.9424 - val_loss: 0.4690 - val_accuracy: 0.9100\n",
      "Epoch 22/50\n",
      "44800/44800 [==============================] - 10s 234us/sample - loss: 0.3181 - accuracy: 0.9411 - val_loss: 0.2994 - val_accuracy: 0.9488\n",
      "Epoch 23/50\n",
      "44800/44800 [==============================] - 10s 233us/sample - loss: 0.3192 - accuracy: 0.9412 - val_loss: 0.3868 - val_accuracy: 0.9312\n",
      "Epoch 24/50\n",
      "44800/44800 [==============================] - 10s 234us/sample - loss: 0.3137 - accuracy: 0.9396 - val_loss: 0.3103 - val_accuracy: 0.9420\n",
      "Epoch 25/50\n",
      "44800/44800 [==============================] - 10s 233us/sample - loss: 0.3194 - accuracy: 0.9422 - val_loss: 0.3018 - val_accuracy: 0.9503\n",
      "Epoch 26/50\n",
      "44800/44800 [==============================] - 11s 235us/sample - loss: 0.3159 - accuracy: 0.9420 - val_loss: 0.2815 - val_accuracy: 0.9518\n",
      "Epoch 27/50\n",
      "44800/44800 [==============================] - 10s 233us/sample - loss: 0.3083 - accuracy: 0.9432 - val_loss: 0.7376 - val_accuracy: 0.8234\n",
      "Epoch 28/50\n",
      "44800/44800 [==============================] - 11s 235us/sample - loss: 0.3070 - accuracy: 0.9417 - val_loss: 0.3771 - val_accuracy: 0.9388\n",
      "Epoch 29/50\n",
      "44800/44800 [==============================] - 10s 233us/sample - loss: 0.3116 - accuracy: 0.9425 - val_loss: 0.3343 - val_accuracy: 0.9403\n",
      "Epoch 30/50\n",
      "44800/44800 [==============================] - 10s 233us/sample - loss: 0.3084 - accuracy: 0.9429 - val_loss: 0.3108 - val_accuracy: 0.9458\n",
      "Epoch 31/50\n",
      "44800/44800 [==============================] - 11s 237us/sample - loss: 0.2993 - accuracy: 0.9445 - val_loss: 0.3536 - val_accuracy: 0.9423\n",
      "Epoch 32/50\n",
      "44800/44800 [==============================] - 11s 236us/sample - loss: 0.2961 - accuracy: 0.9453 - val_loss: 0.3274 - val_accuracy: 0.9455\n",
      "Epoch 33/50\n",
      "44800/44800 [==============================] - 11s 236us/sample - loss: 0.3006 - accuracy: 0.9443 - val_loss: 0.3105 - val_accuracy: 0.9449\n",
      "Epoch 34/50\n",
      "44800/44800 [==============================] - 11s 237us/sample - loss: 0.2898 - accuracy: 0.9469 - val_loss: 0.3781 - val_accuracy: 0.9342\n",
      "Epoch 35/50\n",
      "44800/44800 [==============================] - 10s 234us/sample - loss: 0.2955 - accuracy: 0.9460 - val_loss: 0.3899 - val_accuracy: 0.9289\n",
      "Epoch 36/50\n",
      "44800/44800 [==============================] - 11s 235us/sample - loss: 0.2936 - accuracy: 0.9464 - val_loss: 0.3336 - val_accuracy: 0.9453\n",
      "Epoch 37/50\n",
      "44800/44800 [==============================] - 10s 233us/sample - loss: 0.2858 - accuracy: 0.9478 - val_loss: 0.2869 - val_accuracy: 0.9538\n",
      "Epoch 38/50\n",
      "44800/44800 [==============================] - 10s 233us/sample - loss: 0.2887 - accuracy: 0.9474 - val_loss: 0.3355 - val_accuracy: 0.9439\n",
      "Epoch 39/50\n",
      "44800/44800 [==============================] - 11s 250us/sample - loss: 0.2887 - accuracy: 0.9476 - val_loss: 0.3201 - val_accuracy: 0.9470\n",
      "Epoch 40/50\n",
      "44800/44800 [==============================] - 11s 235us/sample - loss: 0.2870 - accuracy: 0.9483 - val_loss: 0.3334 - val_accuracy: 0.9424\n",
      "Epoch 41/50\n",
      "44800/44800 [==============================] - 10s 234us/sample - loss: 0.2849 - accuracy: 0.9484 - val_loss: 0.3112 - val_accuracy: 0.9466\n",
      "Epoch 42/50\n",
      "44800/44800 [==============================] - 11s 235us/sample - loss: 0.2879 - accuracy: 0.9498 - val_loss: 0.3415 - val_accuracy: 0.9424\n",
      "Epoch 43/50\n",
      "44800/44800 [==============================] - 11s 236us/sample - loss: 0.2748 - accuracy: 0.9504 - val_loss: 0.3333 - val_accuracy: 0.9449\n",
      "Epoch 44/50\n",
      "44800/44800 [==============================] - 10s 233us/sample - loss: 0.2767 - accuracy: 0.9510 - val_loss: 0.3137 - val_accuracy: 0.9453\n",
      "Epoch 45/50\n",
      "44800/44800 [==============================] - 11s 241us/sample - loss: 0.2824 - accuracy: 0.9488 - val_loss: 0.3483 - val_accuracy: 0.9427\n",
      "Epoch 46/50\n",
      "44800/44800 [==============================] - 11s 236us/sample - loss: 0.2817 - accuracy: 0.9494 - val_loss: 0.2795 - val_accuracy: 0.9528\n",
      "Epoch 47/50\n",
      "44800/44800 [==============================] - 11s 256us/sample - loss: 0.2792 - accuracy: 0.9502 - val_loss: 0.2976 - val_accuracy: 0.9508\n",
      "Epoch 48/50\n",
      "44800/44800 [==============================] - 10s 234us/sample - loss: 0.2707 - accuracy: 0.9514 - val_loss: 0.3443 - val_accuracy: 0.9462\n",
      "Epoch 49/50\n",
      "44800/44800 [==============================] - 11s 235us/sample - loss: 0.2773 - accuracy: 0.9506 - val_loss: 0.2663 - val_accuracy: 0.9546\n",
      "Epoch 50/50\n",
      "44800/44800 [==============================] - 10s 234us/sample - loss: 0.2674 - accuracy: 0.9529 - val_loss: 0.2426 - val_accuracy: 0.9576\n",
      "Time:  530.2886888310004\n"
     ]
    }
   ],
   "source": [
    "#4) RMSprop\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.01), loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# Start running time\n",
    "start = timeit.default_timer()\n",
    "\n",
    "# Train the model for 50 epochs using RMSprop\n",
    "rmsProp_metrics = model.fit(X_train, Y_train, batch_size=32, epochs=50, validation_data=(X_val, Y_val), callbacks=[log4])\n",
    "\n",
    "callbacks.append(CSVLogger(log4))\n",
    "\n",
    "# Stop running time\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print(\"Time: \", stop - start) # Time:  626.6540165769984"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSprop Optimizer Performance Metrics:\n",
    "\n",
    "* Overall validation accuracy: 0.9591\n",
    "* Test accuracy: 0.95585\n",
    "* Training time: 10.4 mins\n",
    "* Training loss: 0.2278\n",
    "* Validation loss: 0.2333"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe6d0694668>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_image = x_train[0]\n",
    "plt.imshow(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe7181e8780>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Flipping images vertically with Numpy\n",
    "flipped_vertical = np.fliplr(test_image)\n",
    "plt.imshow(flipped_vertical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe6d019f2b0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Flipping images horizontally with Numpy\n",
    "flipped_horizontal = np.flip(test_image)\n",
    "plt.imshow(flipped_horizontal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe6d0645e10>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Rotate imagges 45 degrees, 7 times, clockwise\n",
    "rotated_img = np.rot90(test_image)\n",
    "plt.imshow(rotated_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe6c25549b0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Rotate images using Scikit-Image: 'angle' = Degrees, 'img' = Input Image\n",
    "# Rotate imagges 45 degrees, 7 times, counterclockwise = 315 degrees or clockwise = -45 (counterclock)\n",
    "from skimage import transform\n",
    "\n",
    "rot1 = transform.rotate(test_image, angle=315)\n",
    "plt.imshow(rot1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import transform\n",
    "\n",
    "# Store X_train augmented images to list\n",
    "augmented_images = []\n",
    "\n",
    "for i in range(x_train.shape[0]):\n",
    "    flip_v = np.fliplr(x_train[i]) # flips images vertically\n",
    "    flip_h = np.flip(x_train[i]) # flips images horizontally\n",
    "    rot1 = transform.rotate(x_train[i], angle=315) # Rotate images 45 degrees = 315 (clockwise) \n",
    "    rot2 = transform.rotate(x_train[i], angle=270)\n",
    "    rot3 = transform.rotate(x_train[i], angle=225)\n",
    "    rot4 = transform.rotate(x_train[i], angle=180)\n",
    "    rot5 = transform.rotate(x_train[i], angle=135)\n",
    "    rot6 = transform.rotate(x_train[i], angle=90)\n",
    "    rot7 = transform.rotate(x_train[i], angle=45)\n",
    "    \n",
    "    # Append all new images to list of augmented_images_Xtrain\n",
    "    augmented_images.append(flip_v)\n",
    "    augmented_images.append(flip_h)\n",
    "    augmented_images.append(rot1)\n",
    "    augmented_images.append(rot2)\n",
    "    augmented_images.append(rot3)\n",
    "    augmented_images.append(rot4)\n",
    "    augmented_images.append(rot5)\n",
    "    augmented_images.append(rot6)\n",
    "    augmented_images.append(rot7)\n",
    "                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(504000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Convert list of augmented images to numpy array\n",
    "aug_train_images_arr = np.asarray(augmented_images)\n",
    "print(aug_train_images_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(504000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Reshape augmented images array to 784\n",
    "aug_img_train = aug_train_images_arr.reshape(aug_train_images_arr.shape[0], 784)\n",
    "print(aug_img_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(548800, 784)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine augmented images to current training set, X_train\n",
    "new_Xtrain = np.concatenate((aug_img_train, X_train))\n",
    "new_Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(548800, 10)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Augment the y_train\n",
    "N = 9 # number of times to clone the y_train array\n",
    "aug_Ytrain = np.vstack([y_train]*N)\n",
    "\n",
    "# One-hot enocode aug_Ytrain\n",
    "n_classes = 10\n",
    "one_hot_Ytrain = np_utils.to_categorical(aug_Ytrain, n_classes)\n",
    "\n",
    "# Combine augmented y_train labels to current y_train\n",
    "new_Ytrain = np.concatenate((one_hot_Ytrain, Y_train))\n",
    "new_Ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the constructor\n",
    "model2 = Sequential()\n",
    "\n",
    "# Add an input layer with 784 neurons and tanh activation\n",
    "model2.add(Dense(num_features, activation='tanh', input_shape=(num_features,)))\n",
    "\n",
    "# Add one hidden layer with 256 neurons and tanh activation\n",
    "model2.add(Dense(num_layers_2, activation='tanh'))\n",
    "\n",
    "# Add an output layer with 10 neurons and softmax activation \n",
    "model2.add(Dense(num_output, activation='softmax'))\n",
    "\n",
    "# Use Momentum (performed the best with trainig data)\n",
    "model2.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.8), loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "548800/548800 [==============================] - 38s 69us/sample - loss: 2.2652\n",
      "Epoch 2/50\n",
      "548800/548800 [==============================] - 38s 68us/sample - loss: 2.2152\n",
      "Epoch 3/50\n",
      "548800/548800 [==============================] - 38s 70us/sample - loss: 2.1929\n",
      "Epoch 4/50\n",
      "548800/548800 [==============================] - 38s 69us/sample - loss: 2.1813\n",
      "Epoch 5/50\n",
      "548800/548800 [==============================] - 38s 69us/sample - loss: 2.1744\n",
      "Epoch 6/50\n",
      "548800/548800 [==============================] - 39s 70us/sample - loss: 2.1689\n",
      "Epoch 7/50\n",
      "548800/548800 [==============================] - 37s 68us/sample - loss: 2.1653\n",
      "Epoch 8/50\n",
      "548800/548800 [==============================] - 37s 68us/sample - loss: 2.1620\n",
      "Epoch 9/50\n",
      "548800/548800 [==============================] - 38s 69us/sample - loss: 2.1592\n",
      "Epoch 10/50\n",
      "548800/548800 [==============================] - 37s 68us/sample - loss: 2.1566\n",
      "Epoch 11/50\n",
      "548800/548800 [==============================] - 38s 68us/sample - loss: 2.1546\n",
      "Epoch 12/50\n",
      "548800/548800 [==============================] - 38s 69us/sample - loss: 2.1527\n",
      "Epoch 13/50\n",
      "548800/548800 [==============================] - 38s 69us/sample - loss: 2.1508\n",
      "Epoch 14/50\n",
      "548800/548800 [==============================] - 38s 70us/sample - loss: 2.1490\n",
      "Epoch 15/50\n",
      "548800/548800 [==============================] - 37s 68us/sample - loss: 2.1478\n",
      "Epoch 16/50\n",
      "548800/548800 [==============================] - 38s 68us/sample - loss: 2.1457\n",
      "Epoch 17/50\n",
      "548800/548800 [==============================] - 38s 69us/sample - loss: 2.1449\n",
      "Epoch 18/50\n",
      "448640/548800 [=======================>......] - ETA: 6s - loss: 2.1430"
     ]
    }
   ],
   "source": [
    "# Train the model for 50 epochs with the augmented images training data \n",
    "model2.fit(new_Xtrain, new_Ytrain, batch_size=128, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using X_test\n",
    "y_pred_aug_data = model2.predict_classes(X_test)\n",
    "\n",
    "# Reshape predictions array (22800,1)\n",
    "y_pred_aug_data = y_pred_aug_data.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Y_Pred\n",
       "0       1\n",
       "1       2\n",
       "2       9\n",
       "3       8\n",
       "4       5"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert y_pred 1D Numpy Array to List\n",
    "y_pred_aug_data = y_pred_aug_data.tolist()\n",
    "\n",
    "# Flatten list of lists\n",
    "y_pred_aug_flat = list(np.concatenate(y_pred_aug_data))\n",
    "\n",
    "predictions2 = pd.DataFrame({\"Y_Pred\": y_pred_aug_flat})\n",
    "predictions2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions2 to CSV file\n",
    "predictions2.to_csv('Q4_prediction_with_augmenation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
